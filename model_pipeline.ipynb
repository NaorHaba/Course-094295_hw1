{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import shap\n",
    "# shap.initjs()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from IPython.display import display"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 100, 'display.max_columns', None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_file = 'data/train_raw.csv'\n",
    "# test_file = 'data/train_raw.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "# read data\n",
    "print('Reading CSV...')\n",
    "t_df = pd.read_csv(train_file, index_col=0, dtype='float')\n",
    "print('Done')\n",
    "t_df['id'] = t_df['id'].astype(int)\n",
    "t_df['id'] = t_df['id'].astype(int)\n",
    "# split train-validation\n",
    "sick = set(t_df[t_df['SepsisLabel'] == 1.0]['id'].unique())\n",
    "healthy = set(t_df['id'].unique()) - sick\n",
    "t_sick = set(random.sample(tuple(sick), int(0.75*len(sick))))\n",
    "v_sick = sick - t_sick\n",
    "t_healthy = set(random.sample(tuple(healthy), int(0.75*len(healthy))))\n",
    "v_healthy = healthy - t_healthy\n",
    "\n",
    "train = t_df[t_df.id.isin(list(t_sick) + list(t_healthy))].sort_values(['id', 'SepsisLabel'])\n",
    "valid = t_df[t_df.id.isin(list(v_sick) + list(v_healthy))].sort_values(['id', 'SepsisLabel'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "                 HR      O2Sat       Temp         SBP        MAP        DBP  \\\n0.0       61.000000  99.000000  36.440000  124.000000  65.000000  43.000000   \n1.0       61.000000  99.000000  36.440000  124.000000  65.000000  43.000000   \n2.0       63.250000  98.250000  36.440000  124.750000  64.250000  41.500000   \n3.0       58.230769  99.461538  36.440000  123.538462  64.769231  41.153846   \n4.0       63.475000  99.150000  36.440000  121.150000  66.275000  42.400000   \n...             ...        ...        ...         ...        ...        ...   \n776714.0  92.990280  97.882567  36.447763  128.615857  89.877763  60.150472   \n776715.0  73.451416  97.098386  37.161072  123.626040  73.992964  52.020070   \n776716.0  73.451416  97.098386  37.161072  123.626040  73.992964  52.020070   \n776717.0  73.050176  97.010936  37.161072  124.847282  76.665763  54.668775   \n776718.0  73.050176  97.010936  37.161072  124.847282  76.665763  54.668775   \n\n               Resp      EtCO2  BaseExcess      HCO3      FiO2        pH  \\\n0.0       17.500000  35.000000    0.000000  0.000000  0.000000  0.000000   \n1.0       17.500000  35.000000    0.000000  0.000000  0.000000  0.000000   \n2.0       24.625000  35.000000    0.000000  0.000000  0.000000  0.000000   \n3.0       13.807692  35.000000    0.000000  0.000000  0.000000  0.000000   \n4.0       20.012500  35.000000    0.000000  0.000000  0.000000  0.000000   \n...             ...        ...         ...       ...       ...       ...   \n776714.0  15.603230  47.057456    0.078947  0.078947  0.236842  0.105263   \n776715.0  15.955769  47.057456    0.076923  0.076923  0.230769  0.102564   \n776716.0  15.955769  47.057456    0.075000  0.075000  0.225000  0.100000   \n776717.0  15.995084  47.057456    0.073171  0.073171  0.219512  0.097561   \n776718.0  15.995084  47.057456    0.071429  0.071429  0.214286  0.095238   \n\n             PaCO2  SaO2  AST       BUN  Alkalinephos   Calcium  Chloride  \\\n0.0       0.000000   0.0  0.0  0.000000           0.0  0.000000  0.000000   \n1.0       0.000000   0.0  0.0  0.000000           0.0  0.000000  0.000000   \n2.0       0.000000   0.0  0.0  0.000000           0.0  0.000000  0.000000   \n3.0       0.000000   0.0  0.0  0.000000           0.0  0.000000  0.000000   \n4.0       0.000000   0.0  0.0  0.000000           0.0  0.000000  0.000000   \n...            ...   ...  ...       ...           ...       ...       ...   \n776714.0  0.078947   0.0  0.0  0.078947           0.0  0.052632  0.078947   \n776715.0  0.076923   0.0  0.0  0.076923           0.0  0.051282  0.076923   \n776716.0  0.075000   0.0  0.0  0.075000           0.0  0.050000  0.075000   \n776717.0  0.073171   0.0  0.0  0.073171           0.0  0.048780  0.073171   \n776718.0  0.071429   0.0  0.0  0.071429           0.0  0.047619  0.071429   \n\n          Creatinine  Bilirubin_direct   Glucose  Lactate  Magnesium  \\\n0.0         0.000000               0.0  0.000000      0.0   0.000000   \n1.0         0.000000               0.0  0.000000      0.0   0.000000   \n2.0         0.000000               0.0  0.000000      0.0   0.000000   \n3.0         0.000000               0.0  0.000000      0.0   0.000000   \n4.0         0.000000               0.0  0.000000      0.0   0.000000   \n...              ...               ...       ...      ...        ...   \n776714.0    0.078947               0.0  0.078947      0.0   0.105263   \n776715.0    0.076923               0.0  0.076923      0.0   0.102564   \n776716.0    0.075000               0.0  0.075000      0.0   0.100000   \n776717.0    0.073171               0.0  0.073171      0.0   0.097561   \n776718.0    0.071429               0.0  0.071429      0.0   0.095238   \n\n          Phosphate  Potassium  Bilirubin_total  TroponinI       Hct  \\\n0.0        0.000000   0.000000              0.0        0.0  0.000000   \n1.0        0.000000   0.000000              0.0        0.0  0.000000   \n2.0        0.000000   0.000000              0.0        0.0  0.000000   \n3.0        0.000000   0.000000              0.0        0.0  0.000000   \n4.0        0.000000   0.000000              0.0        0.0  0.000000   \n...             ...        ...              ...        ...       ...   \n776714.0   0.026316   0.105263              0.0        0.0  0.078947   \n776715.0   0.025641   0.102564              0.0        0.0  0.076923   \n776716.0   0.025000   0.100000              0.0        0.0  0.075000   \n776717.0   0.024390   0.097561              0.0        0.0  0.073171   \n776718.0   0.023810   0.095238              0.0        0.0  0.071429   \n\n               Hgb       PTT       WBC  Fibrinogen  Platelets    Age  Unit1  \\\n0.0       0.000000  0.000000  0.000000         0.0   0.000000  75.91    0.0   \n1.0       0.000000  0.000000  0.000000         0.0   0.000000  75.91    0.0   \n2.0       0.000000  0.000000  0.000000         0.0   0.000000  75.91    0.0   \n3.0       0.000000  0.000000  0.000000         0.0   0.000000  75.91    0.0   \n4.0       0.000000  0.000000  0.000000         0.0   0.000000  75.91    0.0   \n...            ...       ...       ...         ...        ...    ...    ...   \n776714.0  0.078947  0.052632  0.078947         0.0   0.078947  38.75    0.0   \n776715.0  0.076923  0.051282  0.076923         0.0   0.076923  38.75    0.0   \n776716.0  0.075000  0.050000  0.075000         0.0   0.075000  38.75    0.0   \n776717.0  0.073171  0.048780  0.073171         0.0   0.073171  38.75    0.0   \n776718.0  0.071429  0.047619  0.071429         0.0   0.071429  38.75    0.0   \n\n          Unit2  HospAdmTime  ICULOS  SepsisLabel     id  Unit3  Gender_0.0  \\\n0.0         1.0       -98.60     1.0          0.0      0    0.0         1.0   \n1.0         1.0       -98.60     2.0          0.0      0    0.0         1.0   \n2.0         1.0       -98.60     3.0          0.0      0    0.0         1.0   \n3.0         1.0       -98.60     4.0          0.0      0    0.0         1.0   \n4.0         1.0       -98.60     5.0          0.0      0    0.0         1.0   \n...         ...          ...     ...          ...    ...    ...         ...   \n776714.0    1.0        -0.05    38.0          0.0  19998    0.0         0.0   \n776715.0    1.0        -0.05    39.0          0.0  19998    0.0         0.0   \n776716.0    1.0        -0.05    40.0          0.0  19998    0.0         0.0   \n776717.0    1.0        -0.05    41.0          0.0  19998    0.0         0.0   \n776718.0    1.0        -0.05    42.0          0.0  19998    0.0         0.0   \n\n          Gender_1.0  \n0.0              0.0  \n1.0              0.0  \n2.0              0.0  \n3.0              0.0  \n4.0              0.0  \n...              ...  \n776714.0         1.0  \n776715.0         1.0  \n776716.0         1.0  \n776717.0         1.0  \n776718.0         1.0  \n\n[570519 rows x 44 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HR</th>\n      <th>O2Sat</th>\n      <th>Temp</th>\n      <th>SBP</th>\n      <th>MAP</th>\n      <th>DBP</th>\n      <th>Resp</th>\n      <th>EtCO2</th>\n      <th>BaseExcess</th>\n      <th>HCO3</th>\n      <th>FiO2</th>\n      <th>pH</th>\n      <th>PaCO2</th>\n      <th>SaO2</th>\n      <th>AST</th>\n      <th>BUN</th>\n      <th>Alkalinephos</th>\n      <th>Calcium</th>\n      <th>Chloride</th>\n      <th>Creatinine</th>\n      <th>Bilirubin_direct</th>\n      <th>Glucose</th>\n      <th>Lactate</th>\n      <th>Magnesium</th>\n      <th>Phosphate</th>\n      <th>Potassium</th>\n      <th>Bilirubin_total</th>\n      <th>TroponinI</th>\n      <th>Hct</th>\n      <th>Hgb</th>\n      <th>PTT</th>\n      <th>WBC</th>\n      <th>Fibrinogen</th>\n      <th>Platelets</th>\n      <th>Age</th>\n      <th>Unit1</th>\n      <th>Unit2</th>\n      <th>HospAdmTime</th>\n      <th>ICULOS</th>\n      <th>SepsisLabel</th>\n      <th>id</th>\n      <th>Unit3</th>\n      <th>Gender_0.0</th>\n      <th>Gender_1.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>61.000000</td>\n      <td>99.000000</td>\n      <td>36.440000</td>\n      <td>124.000000</td>\n      <td>65.000000</td>\n      <td>43.000000</td>\n      <td>17.500000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>75.91</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-98.60</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>61.000000</td>\n      <td>99.000000</td>\n      <td>36.440000</td>\n      <td>124.000000</td>\n      <td>65.000000</td>\n      <td>43.000000</td>\n      <td>17.500000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>75.91</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-98.60</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>63.250000</td>\n      <td>98.250000</td>\n      <td>36.440000</td>\n      <td>124.750000</td>\n      <td>64.250000</td>\n      <td>41.500000</td>\n      <td>24.625000</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>75.91</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-98.60</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3.0</th>\n      <td>58.230769</td>\n      <td>99.461538</td>\n      <td>36.440000</td>\n      <td>123.538462</td>\n      <td>64.769231</td>\n      <td>41.153846</td>\n      <td>13.807692</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>75.91</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-98.60</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <td>63.475000</td>\n      <td>99.150000</td>\n      <td>36.440000</td>\n      <td>121.150000</td>\n      <td>66.275000</td>\n      <td>42.400000</td>\n      <td>20.012500</td>\n      <td>35.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>75.91</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-98.60</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>776714.0</th>\n      <td>92.990280</td>\n      <td>97.882567</td>\n      <td>36.447763</td>\n      <td>128.615857</td>\n      <td>89.877763</td>\n      <td>60.150472</td>\n      <td>15.603230</td>\n      <td>47.057456</td>\n      <td>0.078947</td>\n      <td>0.078947</td>\n      <td>0.236842</td>\n      <td>0.105263</td>\n      <td>0.078947</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.078947</td>\n      <td>0.0</td>\n      <td>0.052632</td>\n      <td>0.078947</td>\n      <td>0.078947</td>\n      <td>0.0</td>\n      <td>0.078947</td>\n      <td>0.0</td>\n      <td>0.105263</td>\n      <td>0.026316</td>\n      <td>0.105263</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.078947</td>\n      <td>0.078947</td>\n      <td>0.052632</td>\n      <td>0.078947</td>\n      <td>0.0</td>\n      <td>0.078947</td>\n      <td>38.75</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.05</td>\n      <td>38.0</td>\n      <td>0.0</td>\n      <td>19998</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>776715.0</th>\n      <td>73.451416</td>\n      <td>97.098386</td>\n      <td>37.161072</td>\n      <td>123.626040</td>\n      <td>73.992964</td>\n      <td>52.020070</td>\n      <td>15.955769</td>\n      <td>47.057456</td>\n      <td>0.076923</td>\n      <td>0.076923</td>\n      <td>0.230769</td>\n      <td>0.102564</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>0.051282</td>\n      <td>0.076923</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>0.102564</td>\n      <td>0.025641</td>\n      <td>0.102564</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.076923</td>\n      <td>0.076923</td>\n      <td>0.051282</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>0.076923</td>\n      <td>38.75</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.05</td>\n      <td>39.0</td>\n      <td>0.0</td>\n      <td>19998</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>776716.0</th>\n      <td>73.451416</td>\n      <td>97.098386</td>\n      <td>37.161072</td>\n      <td>123.626040</td>\n      <td>73.992964</td>\n      <td>52.020070</td>\n      <td>15.955769</td>\n      <td>47.057456</td>\n      <td>0.075000</td>\n      <td>0.075000</td>\n      <td>0.225000</td>\n      <td>0.100000</td>\n      <td>0.075000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.075000</td>\n      <td>0.0</td>\n      <td>0.050000</td>\n      <td>0.075000</td>\n      <td>0.075000</td>\n      <td>0.0</td>\n      <td>0.075000</td>\n      <td>0.0</td>\n      <td>0.100000</td>\n      <td>0.025000</td>\n      <td>0.100000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.075000</td>\n      <td>0.075000</td>\n      <td>0.050000</td>\n      <td>0.075000</td>\n      <td>0.0</td>\n      <td>0.075000</td>\n      <td>38.75</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.05</td>\n      <td>40.0</td>\n      <td>0.0</td>\n      <td>19998</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>776717.0</th>\n      <td>73.050176</td>\n      <td>97.010936</td>\n      <td>37.161072</td>\n      <td>124.847282</td>\n      <td>76.665763</td>\n      <td>54.668775</td>\n      <td>15.995084</td>\n      <td>47.057456</td>\n      <td>0.073171</td>\n      <td>0.073171</td>\n      <td>0.219512</td>\n      <td>0.097561</td>\n      <td>0.073171</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.073171</td>\n      <td>0.0</td>\n      <td>0.048780</td>\n      <td>0.073171</td>\n      <td>0.073171</td>\n      <td>0.0</td>\n      <td>0.073171</td>\n      <td>0.0</td>\n      <td>0.097561</td>\n      <td>0.024390</td>\n      <td>0.097561</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.073171</td>\n      <td>0.073171</td>\n      <td>0.048780</td>\n      <td>0.073171</td>\n      <td>0.0</td>\n      <td>0.073171</td>\n      <td>38.75</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.05</td>\n      <td>41.0</td>\n      <td>0.0</td>\n      <td>19998</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>776718.0</th>\n      <td>73.050176</td>\n      <td>97.010936</td>\n      <td>37.161072</td>\n      <td>124.847282</td>\n      <td>76.665763</td>\n      <td>54.668775</td>\n      <td>15.995084</td>\n      <td>47.057456</td>\n      <td>0.071429</td>\n      <td>0.071429</td>\n      <td>0.214286</td>\n      <td>0.095238</td>\n      <td>0.071429</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.071429</td>\n      <td>0.0</td>\n      <td>0.047619</td>\n      <td>0.071429</td>\n      <td>0.071429</td>\n      <td>0.0</td>\n      <td>0.071429</td>\n      <td>0.0</td>\n      <td>0.095238</td>\n      <td>0.023810</td>\n      <td>0.095238</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.071429</td>\n      <td>0.071429</td>\n      <td>0.047619</td>\n      <td>0.071429</td>\n      <td>0.0</td>\n      <td>0.071429</td>\n      <td>38.75</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-0.05</td>\n      <td>42.0</td>\n      <td>0.0</td>\n      <td>19998</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>570519 rows × 44 columns</p>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Engineering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Add features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# for each vineyard that has records from 2020 or 2021, find the last 4 years' mean total weight per size\n",
    "# def last_four_years_mean(vineyard_id, year):\n",
    "#     first_list = [2016, 2017, 2018, 2019]\n",
    "#     second_list = [2017, 2018, 2019, 2020]\n",
    "#     if year == 2020:\n",
    "#         weight_df = vine_df.loc[(vine_df['vineyard_id'] == vineyard_id) & (vine_df['measure_year']).isin(first_list)]['plot_total_weight/plot_size']\n",
    "#     else:\n",
    "#         weight_df = vine_df.loc[(vine_df['vineyard_id'] == vineyard_id) & (vine_df['measure_year']).isin(second_list)]['plot_total_weight/plot_size']\n",
    "#     return weight_df.mean(axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregating-Normalizing Features\n",
    "We normalize vital signs by the avg of the feature to get a relative feature value\n",
    "For LR:\n",
    "We aggregate x last hours of features for each patient in train.\n",
    "We aggregate every x hours of features for the patient and return a final prediction in test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "HOURS = 7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "max_cols = ['ICULOS', 'SepsisLabel']\n",
    "mean_cols = [col for col in train if col not in ['id'] + max_cols]\n",
    "X_t = pd.concat([train.groupby('id')[mean_cols].apply(lambda x: x.tail(HOURS).mean()), train.groupby('id')[max_cols].apply(lambda x: x.tail(HOURS).max())], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scaling Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "scaling_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2', 'Age', 'HospAdmTime', 'ICULOS']  # rest are already scaled\n",
    "scaler = MinMaxScaler()\n",
    "X_t[scaling_columns] = scaler.fit_transform(X_t[scaling_columns])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "y_t = X_t['SepsisLabel']\n",
    "X_t = X_t.drop(['SepsisLabel'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "             HR     O2Sat      Temp       SBP       MAP       DBP      Resp  \\\nid                                                                            \n0      0.161853  0.948382  0.435328  0.470862  0.183927  0.158683  0.159127   \n1      0.439165  1.000000  0.636655  0.564638  0.398206  0.335046  0.217865   \n2      0.313071  0.927166  0.497741  0.604998  0.462890  0.466228  0.202119   \n3      0.233610  0.961862  0.562038  0.522588  0.423038  0.461268  0.191409   \n4      0.468750  0.939373  0.536424  0.403750  0.373162  0.362324  0.201356   \n...         ...       ...       ...       ...       ...       ...       ...   \n19993  0.271271  0.988661  0.544126  0.385980  0.279186  0.466228  0.146347   \n19995  0.530675  0.963611  0.616783  0.402349  0.385898  0.406816  0.227637   \n19996  0.212803  0.983380  0.433922  0.556201  0.569145  0.596366  0.170700   \n19997  0.265101  0.978218  0.590528  0.572810  0.409732  0.316105  0.197678   \n19998  0.326040  0.962734  0.533005  0.469192  0.355269  0.302991  0.172023   \n\n          EtCO2  BaseExcess      HCO3      FiO2        pH     PaCO2      SaO2  \\\nid                                                                              \n0      0.277778    0.000000  0.050509  0.000000  0.000000  0.000000  0.000000   \n1      0.277778    0.117489  0.131434  0.242430  0.117489  0.117489  0.000000   \n2      0.277778    0.000000  0.028665  0.085996  0.000000  0.000000  0.000000   \n3      0.277778    0.000000  0.031388  0.000000  0.000000  0.000000  0.000000   \n4      0.277778    0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n...         ...         ...       ...       ...       ...       ...       ...   \n19993  0.411750    0.060699  0.042630  0.267571  0.103329  0.060699  0.039384   \n19995  0.411750    0.077383  0.000000  0.270841  0.154766  0.077383  0.077383   \n19996  0.411750    0.125314  0.050126  0.336024  0.125314  0.125314  0.000000   \n19997  0.411750    0.000000  0.085767  0.000000  0.000000  0.000000  0.000000   \n19998  0.411750    0.077126  0.073158  0.231379  0.098867  0.077126  0.000000   \n\n            AST       BUN  Alkalinephos   Calcium  Chloride  Creatinine  \\\nid                                                                        \n0      0.000000  0.050509      0.000000  0.050509  0.050509    0.050509   \n1      0.000000  0.087623      0.000000  0.087623  0.087623    0.087623   \n2      0.028665  0.028665      0.028665  0.000000  0.028665    0.028665   \n3      0.000000  0.031388      0.000000  0.031388  0.031388    0.031388   \n4      0.000000  0.048058      0.000000  0.048058  0.000000    0.048058   \n...         ...       ...           ...       ...       ...         ...   \n19993  0.000000  0.042630      0.000000  0.042630  0.042630    0.042630   \n19995  0.000000  0.038692      0.000000  0.000000  0.000000    0.038692   \n19996  0.000000  0.050126      0.000000  0.050126  0.050126    0.050126   \n19997  0.000000  0.085767      0.000000  0.085767  0.085767    0.085767   \n19998  0.000000  0.073158      0.000000  0.051418  0.073158    0.073158   \n\n       Bilirubin_direct   Glucose   Lactate  Magnesium  Phosphate  Potassium  \\\nid                                                                             \n0                   0.0  0.050509  0.000000   0.050509   0.050509   0.050509   \n1                   0.0  0.205112  0.117489   0.087623   0.087623   0.087623   \n2                   0.0  0.028665  0.000000   0.028665   0.000000   0.028665   \n3                   0.0  0.075920  0.000000   0.031388   0.031388   0.031388   \n4                   0.0  0.204395  0.000000   0.096116   0.000000   0.096116   \n...                 ...       ...       ...        ...        ...        ...   \n19993               0.0  0.124645  0.048133   0.051379   0.051379   0.090763   \n19995               0.0  0.154766  0.000000   0.000000   0.000000   0.000000   \n19996               0.0  0.050126  0.025063   0.050126   0.050126   0.050126   \n19997               0.0  0.085767  0.000000   0.085767   0.085767   0.085767   \n19998               0.0  0.073158  0.000000   0.098867   0.025709   0.098867   \n\n       Bilirubin_total  TroponinI       Hct       Hgb       PTT       WBC  \\\nid                                                                          \n0             0.000000        0.0  0.050509  0.050509  0.000000  0.050509   \n1             0.000000        0.0  0.131434  0.131434  0.087623  0.087623   \n2             0.028665        0.0  0.028665  0.028665  0.028665  0.028665   \n3             0.000000        0.0  0.031388  0.031388  0.031388  0.031388   \n4             0.000000        0.0  0.048058  0.048058  0.000000  0.048058   \n...                ...        ...       ...       ...       ...       ...   \n19993         0.000000        0.0  0.197339  0.103329  0.039384  0.042630   \n19995         0.000000        0.0  0.181294  0.181294  0.000000  0.000000   \n19996         0.000000        0.0  0.075188  0.025063  0.000000  0.025063   \n19997         0.000000        0.0  0.085767  0.085767  0.085767  0.085767   \n19998         0.000000        0.0  0.073158  0.073158  0.051418  0.073158   \n\n       Fibrinogen  Platelets       Age  Unit1  Unit2  HospAdmTime  Unit3  \\\nid                                                                         \n0             0.0   0.050509  0.716588    0.0    1.0     0.968900    0.0   \n1             0.0   0.087623  0.597529    0.0    0.0     0.995343    1.0   \n2             0.0   0.028665  0.445647    1.0    0.0     0.995346    0.0   \n3             0.0   0.031388  0.406118    0.0    0.0     0.995343    1.0   \n4             0.0   0.048058  0.682353    1.0    0.0     0.937774    0.0   \n...           ...        ...       ...    ...    ...          ...    ...   \n19993         0.0   0.042630  0.378471    0.0    0.0     0.995341    1.0   \n19995         0.0   0.000000  0.526000    0.0    1.0     0.994244    0.0   \n19996         0.0   0.025063  0.598000    0.0    0.0     0.995341    1.0   \n19997         0.0   0.085767  0.757882    1.0    0.0     0.995343    0.0   \n19998         0.0   0.073158  0.279412    0.0    1.0     0.995335    0.0   \n\n       Gender_0.0  Gender_1.0    ICULOS  \nid                                       \n0             1.0         0.0  0.065672  \n1             0.0         1.0  0.074627  \n2             0.0         1.0  0.110448  \n3             0.0         1.0  0.140299  \n4             0.0         1.0  0.068657  \n...           ...         ...       ...  \n19993         0.0         1.0  0.146269  \n19995         0.0         1.0  0.083582  \n19996         0.0         1.0  0.125373  \n19997         1.0         0.0  0.041791  \n19998         0.0         1.0  0.122388  \n\n[14999 rows x 42 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HR</th>\n      <th>O2Sat</th>\n      <th>Temp</th>\n      <th>SBP</th>\n      <th>MAP</th>\n      <th>DBP</th>\n      <th>Resp</th>\n      <th>EtCO2</th>\n      <th>BaseExcess</th>\n      <th>HCO3</th>\n      <th>FiO2</th>\n      <th>pH</th>\n      <th>PaCO2</th>\n      <th>SaO2</th>\n      <th>AST</th>\n      <th>BUN</th>\n      <th>Alkalinephos</th>\n      <th>Calcium</th>\n      <th>Chloride</th>\n      <th>Creatinine</th>\n      <th>Bilirubin_direct</th>\n      <th>Glucose</th>\n      <th>Lactate</th>\n      <th>Magnesium</th>\n      <th>Phosphate</th>\n      <th>Potassium</th>\n      <th>Bilirubin_total</th>\n      <th>TroponinI</th>\n      <th>Hct</th>\n      <th>Hgb</th>\n      <th>PTT</th>\n      <th>WBC</th>\n      <th>Fibrinogen</th>\n      <th>Platelets</th>\n      <th>Age</th>\n      <th>Unit1</th>\n      <th>Unit2</th>\n      <th>HospAdmTime</th>\n      <th>Unit3</th>\n      <th>Gender_0.0</th>\n      <th>Gender_1.0</th>\n      <th>ICULOS</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.161853</td>\n      <td>0.948382</td>\n      <td>0.435328</td>\n      <td>0.470862</td>\n      <td>0.183927</td>\n      <td>0.158683</td>\n      <td>0.159127</td>\n      <td>0.277778</td>\n      <td>0.000000</td>\n      <td>0.050509</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.050509</td>\n      <td>0.000000</td>\n      <td>0.050509</td>\n      <td>0.050509</td>\n      <td>0.050509</td>\n      <td>0.0</td>\n      <td>0.050509</td>\n      <td>0.000000</td>\n      <td>0.050509</td>\n      <td>0.050509</td>\n      <td>0.050509</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.050509</td>\n      <td>0.050509</td>\n      <td>0.000000</td>\n      <td>0.050509</td>\n      <td>0.0</td>\n      <td>0.050509</td>\n      <td>0.716588</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.968900</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.065672</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.439165</td>\n      <td>1.000000</td>\n      <td>0.636655</td>\n      <td>0.564638</td>\n      <td>0.398206</td>\n      <td>0.335046</td>\n      <td>0.217865</td>\n      <td>0.277778</td>\n      <td>0.117489</td>\n      <td>0.131434</td>\n      <td>0.242430</td>\n      <td>0.117489</td>\n      <td>0.117489</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.087623</td>\n      <td>0.000000</td>\n      <td>0.087623</td>\n      <td>0.087623</td>\n      <td>0.087623</td>\n      <td>0.0</td>\n      <td>0.205112</td>\n      <td>0.117489</td>\n      <td>0.087623</td>\n      <td>0.087623</td>\n      <td>0.087623</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.131434</td>\n      <td>0.131434</td>\n      <td>0.087623</td>\n      <td>0.087623</td>\n      <td>0.0</td>\n      <td>0.087623</td>\n      <td>0.597529</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.995343</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.074627</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.313071</td>\n      <td>0.927166</td>\n      <td>0.497741</td>\n      <td>0.604998</td>\n      <td>0.462890</td>\n      <td>0.466228</td>\n      <td>0.202119</td>\n      <td>0.277778</td>\n      <td>0.000000</td>\n      <td>0.028665</td>\n      <td>0.085996</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.028665</td>\n      <td>0.028665</td>\n      <td>0.028665</td>\n      <td>0.000000</td>\n      <td>0.028665</td>\n      <td>0.028665</td>\n      <td>0.0</td>\n      <td>0.028665</td>\n      <td>0.000000</td>\n      <td>0.028665</td>\n      <td>0.000000</td>\n      <td>0.028665</td>\n      <td>0.028665</td>\n      <td>0.0</td>\n      <td>0.028665</td>\n      <td>0.028665</td>\n      <td>0.028665</td>\n      <td>0.028665</td>\n      <td>0.0</td>\n      <td>0.028665</td>\n      <td>0.445647</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.995346</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.110448</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.233610</td>\n      <td>0.961862</td>\n      <td>0.562038</td>\n      <td>0.522588</td>\n      <td>0.423038</td>\n      <td>0.461268</td>\n      <td>0.191409</td>\n      <td>0.277778</td>\n      <td>0.000000</td>\n      <td>0.031388</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.031388</td>\n      <td>0.000000</td>\n      <td>0.031388</td>\n      <td>0.031388</td>\n      <td>0.031388</td>\n      <td>0.0</td>\n      <td>0.075920</td>\n      <td>0.000000</td>\n      <td>0.031388</td>\n      <td>0.031388</td>\n      <td>0.031388</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.031388</td>\n      <td>0.031388</td>\n      <td>0.031388</td>\n      <td>0.031388</td>\n      <td>0.0</td>\n      <td>0.031388</td>\n      <td>0.406118</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.995343</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.140299</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.468750</td>\n      <td>0.939373</td>\n      <td>0.536424</td>\n      <td>0.403750</td>\n      <td>0.373162</td>\n      <td>0.362324</td>\n      <td>0.201356</td>\n      <td>0.277778</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.048058</td>\n      <td>0.000000</td>\n      <td>0.048058</td>\n      <td>0.000000</td>\n      <td>0.048058</td>\n      <td>0.0</td>\n      <td>0.204395</td>\n      <td>0.000000</td>\n      <td>0.096116</td>\n      <td>0.000000</td>\n      <td>0.096116</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.048058</td>\n      <td>0.048058</td>\n      <td>0.000000</td>\n      <td>0.048058</td>\n      <td>0.0</td>\n      <td>0.048058</td>\n      <td>0.682353</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.937774</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.068657</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19993</th>\n      <td>0.271271</td>\n      <td>0.988661</td>\n      <td>0.544126</td>\n      <td>0.385980</td>\n      <td>0.279186</td>\n      <td>0.466228</td>\n      <td>0.146347</td>\n      <td>0.411750</td>\n      <td>0.060699</td>\n      <td>0.042630</td>\n      <td>0.267571</td>\n      <td>0.103329</td>\n      <td>0.060699</td>\n      <td>0.039384</td>\n      <td>0.000000</td>\n      <td>0.042630</td>\n      <td>0.000000</td>\n      <td>0.042630</td>\n      <td>0.042630</td>\n      <td>0.042630</td>\n      <td>0.0</td>\n      <td>0.124645</td>\n      <td>0.048133</td>\n      <td>0.051379</td>\n      <td>0.051379</td>\n      <td>0.090763</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.197339</td>\n      <td>0.103329</td>\n      <td>0.039384</td>\n      <td>0.042630</td>\n      <td>0.0</td>\n      <td>0.042630</td>\n      <td>0.378471</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.995341</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.146269</td>\n    </tr>\n    <tr>\n      <th>19995</th>\n      <td>0.530675</td>\n      <td>0.963611</td>\n      <td>0.616783</td>\n      <td>0.402349</td>\n      <td>0.385898</td>\n      <td>0.406816</td>\n      <td>0.227637</td>\n      <td>0.411750</td>\n      <td>0.077383</td>\n      <td>0.000000</td>\n      <td>0.270841</td>\n      <td>0.154766</td>\n      <td>0.077383</td>\n      <td>0.077383</td>\n      <td>0.000000</td>\n      <td>0.038692</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.038692</td>\n      <td>0.0</td>\n      <td>0.154766</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.181294</td>\n      <td>0.181294</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.526000</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.994244</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.083582</td>\n    </tr>\n    <tr>\n      <th>19996</th>\n      <td>0.212803</td>\n      <td>0.983380</td>\n      <td>0.433922</td>\n      <td>0.556201</td>\n      <td>0.569145</td>\n      <td>0.596366</td>\n      <td>0.170700</td>\n      <td>0.411750</td>\n      <td>0.125314</td>\n      <td>0.050126</td>\n      <td>0.336024</td>\n      <td>0.125314</td>\n      <td>0.125314</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.050126</td>\n      <td>0.000000</td>\n      <td>0.050126</td>\n      <td>0.050126</td>\n      <td>0.050126</td>\n      <td>0.0</td>\n      <td>0.050126</td>\n      <td>0.025063</td>\n      <td>0.050126</td>\n      <td>0.050126</td>\n      <td>0.050126</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.075188</td>\n      <td>0.025063</td>\n      <td>0.000000</td>\n      <td>0.025063</td>\n      <td>0.0</td>\n      <td>0.025063</td>\n      <td>0.598000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.995341</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.125373</td>\n    </tr>\n    <tr>\n      <th>19997</th>\n      <td>0.265101</td>\n      <td>0.978218</td>\n      <td>0.590528</td>\n      <td>0.572810</td>\n      <td>0.409732</td>\n      <td>0.316105</td>\n      <td>0.197678</td>\n      <td>0.411750</td>\n      <td>0.000000</td>\n      <td>0.085767</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.085767</td>\n      <td>0.000000</td>\n      <td>0.085767</td>\n      <td>0.085767</td>\n      <td>0.085767</td>\n      <td>0.0</td>\n      <td>0.085767</td>\n      <td>0.000000</td>\n      <td>0.085767</td>\n      <td>0.085767</td>\n      <td>0.085767</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.085767</td>\n      <td>0.085767</td>\n      <td>0.085767</td>\n      <td>0.085767</td>\n      <td>0.0</td>\n      <td>0.085767</td>\n      <td>0.757882</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.995343</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.041791</td>\n    </tr>\n    <tr>\n      <th>19998</th>\n      <td>0.326040</td>\n      <td>0.962734</td>\n      <td>0.533005</td>\n      <td>0.469192</td>\n      <td>0.355269</td>\n      <td>0.302991</td>\n      <td>0.172023</td>\n      <td>0.411750</td>\n      <td>0.077126</td>\n      <td>0.073158</td>\n      <td>0.231379</td>\n      <td>0.098867</td>\n      <td>0.077126</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.073158</td>\n      <td>0.000000</td>\n      <td>0.051418</td>\n      <td>0.073158</td>\n      <td>0.073158</td>\n      <td>0.0</td>\n      <td>0.073158</td>\n      <td>0.000000</td>\n      <td>0.098867</td>\n      <td>0.025709</td>\n      <td>0.098867</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.073158</td>\n      <td>0.073158</td>\n      <td>0.051418</td>\n      <td>0.073158</td>\n      <td>0.0</td>\n      <td>0.073158</td>\n      <td>0.279412</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.995335</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.122388</td>\n    </tr>\n  </tbody>\n</table>\n<p>14999 rows × 42 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting Features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen numeric columns: Index(['HR', 'O2Sat', 'Temp', 'SBP', 'DBP', 'Resp', 'EtCO2', 'FiO2', 'BUN',\n",
      "       'Creatinine', 'Bilirubin_direct', 'Glucose', 'Magnesium', 'Phosphate',\n",
      "       'Hgb', 'WBC', 'Fibrinogen', 'Unit1', 'Unit2', 'Unit3', 'ICULOS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "sfs = SequentialFeatureSelector(LogisticRegression(), n_features_to_select=0.5, scoring='f1', n_jobs=-1)\n",
    "sfs = sfs.fit(X_t, y_t)\n",
    "chosen_numeric = X_t.columns[sfs.support_]\n",
    "print('Chosen numeric columns:', chosen_numeric)\n",
    "X_t = pd.DataFrame(sfs.transform(X_t), columns=chosen_numeric, index=X_t.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0.10097431355181576"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=0, scoring='f1', max_iter=10000).fit(X_t, y_t)\n",
    "\n",
    "clf.score(X_t, y_t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          HR     O2Sat      Temp       SBP       DBP      Resp     EtCO2  \\\n",
      "id                                                                         \n",
      "0   0.161853  0.948382  0.435328  0.470862  0.158683  0.159127  0.277778   \n",
      "1   0.439165  1.000000  0.636655  0.564638  0.335046  0.217865  0.277778   \n",
      "2   0.313071  0.927166  0.497741  0.604998  0.466228  0.202119  0.277778   \n",
      "3   0.233610  0.961862  0.562038  0.522588  0.461268  0.191409  0.277778   \n",
      "4   0.468750  0.939373  0.536424  0.403750  0.362324  0.201356  0.277778   \n",
      "\n",
      "        FiO2       BUN  Creatinine  Bilirubin_direct   Glucose  Magnesium  \\\n",
      "id                                                                          \n",
      "0   0.000000  0.050509    0.050509               0.0  0.050509   0.050509   \n",
      "1   0.242430  0.087623    0.087623               0.0  0.205112   0.087623   \n",
      "2   0.085996  0.028665    0.028665               0.0  0.028665   0.028665   \n",
      "3   0.000000  0.031388    0.031388               0.0  0.075920   0.031388   \n",
      "4   0.000000  0.048058    0.048058               0.0  0.204395   0.096116   \n",
      "\n",
      "    Phosphate       Hgb       WBC  Fibrinogen  Unit1  Unit2  Unit3    ICULOS  \n",
      "id                                                                            \n",
      "0    0.050509  0.050509  0.050509         0.0    0.0    1.0    0.0  0.065672  \n",
      "1    0.087623  0.131434  0.087623         0.0    0.0    0.0    1.0  0.074627  \n",
      "2    0.000000  0.028665  0.028665         0.0    1.0    0.0    0.0  0.110448  \n",
      "3    0.031388  0.031388  0.031388         0.0    0.0    0.0    1.0  0.140299  \n",
      "4    0.000000  0.048058  0.048058         0.0    1.0    0.0    0.0  0.068657  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=5)\n",
    "\n",
    "for i in X_t.rolling(indexer):\n",
    "    print(i)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14 candidates, totalling 70 fits\n",
      "[Pipeline] ......... (step 1 of 1) Processing estimator, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n0        0.206001      0.015150         0.005399        0.001960   \n1        0.171600      0.013590         0.004002        0.003520   \n2        0.011402      0.013821         0.004998        0.003033   \n3        0.337801      0.038614         0.004398        0.001743   \n4        0.033400      0.003496         0.002598        0.000491   \n5        0.005198      0.000400         0.002402        0.000490   \n6        0.005000      0.000001         0.003201        0.000400   \n7        0.005599      0.000801         0.003202        0.000401   \n8        0.003201      0.000402         0.003401        0.000798   \n9        0.003000      0.000003         0.003801        0.000399   \n10       0.004799      0.002224         0.003998        0.001788   \n11       0.005999      0.003099         0.003801        0.000980   \n12       0.005202      0.002401         0.005398        0.002414   \n13       0.003801      0.000750         0.003599        0.001018   \n\n                              param_estimator param_estimator__kernel  \\\n0                              ElasticNetCV()                     NaN   \n1                                   LassoCV()                     NaN   \n2   RidgeCV(alphas=array([ 0.1,  1. , 10. ]))                     NaN   \n3                              MLPRegressor()                     NaN   \n4                        SVR(kernel='linear')                  linear   \n5                        SVR(kernel='linear')                    poly   \n6                        SVR(kernel='linear')                     rbf   \n7                        SVR(kernel='linear')                 sigmoid   \n8                       KNeighborsRegressor()                     NaN   \n9                       KNeighborsRegressor()                     NaN   \n10                      KNeighborsRegressor()                     NaN   \n11                      KNeighborsRegressor()                     NaN   \n12                      KNeighborsRegressor()                     NaN   \n13                      KNeighborsRegressor()                     NaN   \n\n   param_estimator__n_neighbors param_estimator__weights  \\\n0                           NaN                      NaN   \n1                           NaN                      NaN   \n2                           NaN                      NaN   \n3                           NaN                      NaN   \n4                           NaN                      NaN   \n5                           NaN                      NaN   \n6                           NaN                      NaN   \n7                           NaN                      NaN   \n8                             3                  uniform   \n9                             3                 distance   \n10                            5                  uniform   \n11                            5                 distance   \n12                            7                  uniform   \n13                            7                 distance   \n\n                                               params  split0_test_score  \\\n0                       {'estimator': ElasticNetCV()}          -0.578538   \n1                            {'estimator': LassoCV()}          -0.545916   \n2   {'estimator': RidgeCV(alphas=array([ 0.1,  1. ...          -0.664350   \n3                       {'estimator': MLPRegressor()}          -0.525335   \n4   {'estimator': SVR(kernel='linear'), 'estimator...          -0.499866   \n5   {'estimator': SVR(kernel='linear'), 'estimator...          -0.580673   \n6   {'estimator': SVR(kernel='linear'), 'estimator...          -0.582752   \n7   {'estimator': SVR(kernel='linear'), 'estimator...          -0.515376   \n8   {'estimator': KNeighborsRegressor(), 'estimato...          -0.624236   \n9   {'estimator': KNeighborsRegressor(), 'estimato...          -0.618345   \n10  {'estimator': KNeighborsRegressor(), 'estimato...          -0.572498   \n11  {'estimator': KNeighborsRegressor(), 'estimato...          -0.564308   \n12  {'estimator': KNeighborsRegressor(), 'estimato...          -0.675445   \n13  {'estimator': KNeighborsRegressor(), 'estimato...          -0.660884   \n\n    split1_test_score  split2_test_score  split3_test_score  \\\n0           -0.315665          -0.274876          -0.271324   \n1           -0.322415          -0.268467          -0.262123   \n2           -0.295874          -0.255139          -0.288527   \n3           -0.447063          -0.308089          -0.379082   \n4           -0.316407          -0.239394          -0.255430   \n5           -0.451622          -0.310811          -0.445034   \n6           -0.426199          -0.266225          -0.276553   \n7           -0.439301          -0.322205          -0.397498   \n8           -0.434992          -0.296314          -0.249175   \n9           -0.431008          -0.293183          -0.244858   \n10          -0.451729          -0.278854          -0.299957   \n11          -0.448192          -0.274800          -0.290651   \n12          -0.405226          -0.244970          -0.323748   \n13          -0.405855          -0.244828          -0.313165   \n\n    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n0           -0.398687        -0.367818        0.114913                3  \n1           -0.402492        -0.360283        0.105585                2  \n2           -0.386913        -0.378160        0.149613                4  \n3           -0.417340        -0.415382        0.072009               12  \n4           -0.412406        -0.344700        0.098508                1  \n5           -0.433055        -0.444239        0.085554               14  \n6           -0.379663        -0.386278        0.115492                8  \n7           -0.544528        -0.443782        0.080273               13  \n8           -0.344764        -0.389896        0.132322                9  \n9           -0.341003        -0.385679        0.131583                7  \n10          -0.316261        -0.383860        0.112095                6  \n11          -0.313733        -0.378337        0.111398                5  \n12          -0.340786        -0.398035        0.147806               11  \n13          -0.336403        -0.392227        0.143844               10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_estimator</th>\n      <th>param_estimator__kernel</th>\n      <th>param_estimator__n_neighbors</th>\n      <th>param_estimator__weights</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.206001</td>\n      <td>0.015150</td>\n      <td>0.005399</td>\n      <td>0.001960</td>\n      <td>ElasticNetCV()</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': ElasticNetCV()}</td>\n      <td>-0.578538</td>\n      <td>-0.315665</td>\n      <td>-0.274876</td>\n      <td>-0.271324</td>\n      <td>-0.398687</td>\n      <td>-0.367818</td>\n      <td>0.114913</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.171600</td>\n      <td>0.013590</td>\n      <td>0.004002</td>\n      <td>0.003520</td>\n      <td>LassoCV()</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': LassoCV()}</td>\n      <td>-0.545916</td>\n      <td>-0.322415</td>\n      <td>-0.268467</td>\n      <td>-0.262123</td>\n      <td>-0.402492</td>\n      <td>-0.360283</td>\n      <td>0.105585</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.011402</td>\n      <td>0.013821</td>\n      <td>0.004998</td>\n      <td>0.003033</td>\n      <td>RidgeCV(alphas=array([ 0.1,  1. , 10. ]))</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': RidgeCV(alphas=array([ 0.1,  1. ...</td>\n      <td>-0.664350</td>\n      <td>-0.295874</td>\n      <td>-0.255139</td>\n      <td>-0.288527</td>\n      <td>-0.386913</td>\n      <td>-0.378160</td>\n      <td>0.149613</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.337801</td>\n      <td>0.038614</td>\n      <td>0.004398</td>\n      <td>0.001743</td>\n      <td>MLPRegressor()</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': MLPRegressor()}</td>\n      <td>-0.525335</td>\n      <td>-0.447063</td>\n      <td>-0.308089</td>\n      <td>-0.379082</td>\n      <td>-0.417340</td>\n      <td>-0.415382</td>\n      <td>0.072009</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.033400</td>\n      <td>0.003496</td>\n      <td>0.002598</td>\n      <td>0.000491</td>\n      <td>SVR(kernel='linear')</td>\n      <td>linear</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': SVR(kernel='linear'), 'estimator...</td>\n      <td>-0.499866</td>\n      <td>-0.316407</td>\n      <td>-0.239394</td>\n      <td>-0.255430</td>\n      <td>-0.412406</td>\n      <td>-0.344700</td>\n      <td>0.098508</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.005198</td>\n      <td>0.000400</td>\n      <td>0.002402</td>\n      <td>0.000490</td>\n      <td>SVR(kernel='linear')</td>\n      <td>poly</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': SVR(kernel='linear'), 'estimator...</td>\n      <td>-0.580673</td>\n      <td>-0.451622</td>\n      <td>-0.310811</td>\n      <td>-0.445034</td>\n      <td>-0.433055</td>\n      <td>-0.444239</td>\n      <td>0.085554</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.005000</td>\n      <td>0.000001</td>\n      <td>0.003201</td>\n      <td>0.000400</td>\n      <td>SVR(kernel='linear')</td>\n      <td>rbf</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': SVR(kernel='linear'), 'estimator...</td>\n      <td>-0.582752</td>\n      <td>-0.426199</td>\n      <td>-0.266225</td>\n      <td>-0.276553</td>\n      <td>-0.379663</td>\n      <td>-0.386278</td>\n      <td>0.115492</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.005599</td>\n      <td>0.000801</td>\n      <td>0.003202</td>\n      <td>0.000401</td>\n      <td>SVR(kernel='linear')</td>\n      <td>sigmoid</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'estimator': SVR(kernel='linear'), 'estimator...</td>\n      <td>-0.515376</td>\n      <td>-0.439301</td>\n      <td>-0.322205</td>\n      <td>-0.397498</td>\n      <td>-0.544528</td>\n      <td>-0.443782</td>\n      <td>0.080273</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.003201</td>\n      <td>0.000402</td>\n      <td>0.003401</td>\n      <td>0.000798</td>\n      <td>KNeighborsRegressor()</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>uniform</td>\n      <td>{'estimator': KNeighborsRegressor(), 'estimato...</td>\n      <td>-0.624236</td>\n      <td>-0.434992</td>\n      <td>-0.296314</td>\n      <td>-0.249175</td>\n      <td>-0.344764</td>\n      <td>-0.389896</td>\n      <td>0.132322</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.003000</td>\n      <td>0.000003</td>\n      <td>0.003801</td>\n      <td>0.000399</td>\n      <td>KNeighborsRegressor()</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>distance</td>\n      <td>{'estimator': KNeighborsRegressor(), 'estimato...</td>\n      <td>-0.618345</td>\n      <td>-0.431008</td>\n      <td>-0.293183</td>\n      <td>-0.244858</td>\n      <td>-0.341003</td>\n      <td>-0.385679</td>\n      <td>0.131583</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.004799</td>\n      <td>0.002224</td>\n      <td>0.003998</td>\n      <td>0.001788</td>\n      <td>KNeighborsRegressor()</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>uniform</td>\n      <td>{'estimator': KNeighborsRegressor(), 'estimato...</td>\n      <td>-0.572498</td>\n      <td>-0.451729</td>\n      <td>-0.278854</td>\n      <td>-0.299957</td>\n      <td>-0.316261</td>\n      <td>-0.383860</td>\n      <td>0.112095</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.005999</td>\n      <td>0.003099</td>\n      <td>0.003801</td>\n      <td>0.000980</td>\n      <td>KNeighborsRegressor()</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>distance</td>\n      <td>{'estimator': KNeighborsRegressor(), 'estimato...</td>\n      <td>-0.564308</td>\n      <td>-0.448192</td>\n      <td>-0.274800</td>\n      <td>-0.290651</td>\n      <td>-0.313733</td>\n      <td>-0.378337</td>\n      <td>0.111398</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.005202</td>\n      <td>0.002401</td>\n      <td>0.005398</td>\n      <td>0.002414</td>\n      <td>KNeighborsRegressor()</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>uniform</td>\n      <td>{'estimator': KNeighborsRegressor(), 'estimato...</td>\n      <td>-0.675445</td>\n      <td>-0.405226</td>\n      <td>-0.244970</td>\n      <td>-0.323748</td>\n      <td>-0.340786</td>\n      <td>-0.398035</td>\n      <td>0.147806</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.003801</td>\n      <td>0.000750</td>\n      <td>0.003599</td>\n      <td>0.001018</td>\n      <td>KNeighborsRegressor()</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>distance</td>\n      <td>{'estimator': KNeighborsRegressor(), 'estimato...</td>\n      <td>-0.660884</td>\n      <td>-0.405855</td>\n      <td>-0.244828</td>\n      <td>-0.313165</td>\n      <td>-0.336403</td>\n      <td>-0.392227</td>\n      <td>0.143844</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline(\n",
    "    steps=[\n",
    "        ('estimator', ElasticNetCV())\n",
    "    ],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    {\n",
    "        \"estimator\": [\n",
    "            ElasticNetCV(),\n",
    "            LassoCV(),\n",
    "            RidgeCV(),\n",
    "            MLPRegressor()\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"estimator\": [SVR()],\n",
    "        \"estimator__kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "    },\n",
    "    {\n",
    "        \"estimator\": [KNeighborsRegressor()],\n",
    "        \"estimator__n_neighbors\": [3, 5, 7],\n",
    "        \"estimator__weights\": ['uniform', 'distance']\n",
    "    }\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(model,\n",
    "                    param_grid=estimators,\n",
    "                    scoring='neg_mean_absolute_percentage_error',\n",
    "                    refit=True,\n",
    "                    cv=5,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=10)\n",
    "\n",
    "grid.fit(X_features, y)\n",
    "pd.DataFrame(grid.cv_results_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "X_train,X_test,y_train,y_test  = train_test_split(X_features, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# rather than use the whole training set to estimate expected values, we summarize with\n",
    "# a set of weighted kmeans, each weighted by the number of points they represent.\n",
    "X_train_summary = shap.kmeans(X_train, 10)\n",
    "\n",
    "def print_accuracy(f):\n",
    "    print(\"Root mean squared test error = {0}\".format(np.sqrt(np.mean((f(X_test) - y_test)**2))))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared test error = 0.8512233162752305\n"
     ]
    }
   ],
   "source": [
    "model = SVR(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_accuracy(model.predict)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "data": {
      "text/plain": "<shap.plots._force.AdditiveForceVisualizer at 0x1d8a3b0fc40>",
      "text/html": "\n<div id='iKTNTZ4CW42CL9R2E566E'>\n<div style='color: #900; text-align: center;'>\n  <b>Visualization omitted, Javascript library not loaded!</b><br>\n  Have you run `initjs()` in this notebook? If this notebook was from another\n  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n  this notebook on github the Javascript has been stripped for security. If you are using\n  JupyterLab this error is because a JupyterLab extension has not yet been written.\n</div></div>\n <script>\n   if (window.SHAP) SHAP.ReactDom.render(\n    SHAP.React.createElement(SHAP.AdditiveForceVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": 1.5284008825152238, \"outValue\": 0.9921435416093073, \"link\": \"identity\", \"featureNames\": [\"plot_size\", \"wine_series\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"N_nitrogen\", \"N_general\", \"P_burn\", \"K_burn\", \"Mg_burn\", \"Ca_burn\", \"Na_burn\", \"B_burn\", \"chlorine\", \"iron\", \"zinc\", \"manganese\", \"copper\", \"last_four_years_mean\"], \"features\": {\"0\": {\"effect\": -0.06777247404157366, \"value\": -0.7471833070360794}, \"1\": {\"effect\": 0.032014789282876106, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.05560078990262822, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10386867050831103, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.18199530268063563, \"value\": -1.5240757820298299}, \"5\": {\"effect\": -0.17430498162123115, \"value\": -0.83074430754918}, \"6\": {\"effect\": -0.051948537183390604, \"value\": -0.6124883534205269}, \"7\": {\"effect\": -0.008217705221333253, \"value\": -0.7302358547297587}, \"8\": {\"effect\": -0.050498054697491385, \"value\": -0.5090958014198733}, \"9\": {\"effect\": -0.03971921861870315, \"value\": -0.7864482792622125}, \"10\": {\"effect\": -0.09523314394059049, \"value\": -1.6089823126100216}, \"11\": {\"effect\": 0.029810905243836595, \"value\": -1.0672760476077034}, \"12\": {\"effect\": -0.0053499020081325625, \"value\": -0.45334848051375276}, \"13\": {\"effect\": -0.0834503865094931, \"value\": -0.9916995666145361}, \"15\": {\"effect\": 0.05517058418579253, \"value\": 1.126387010958939}, \"16\": {\"effect\": 0.12080922166930093, \"value\": -1.069896198751978}, \"17\": {\"effect\": -0.030041698771975735, \"value\": -1.2175397879519287}, \"18\": {\"effect\": 0.010398843160644758, \"value\": 0.2085772618764899}, \"20\": {\"effect\": -0.013308455439380758, \"value\": -0.36584217562607535}, \"21\": {\"effect\": 0.014299603878358514, \"value\": 1.6966266872398186}, \"22\": {\"effect\": -0.5203814933650049, \"value\": -0.7419759979103228}}, \"plot_cmap\": \"RdBu\", \"labelMargin\": 20}),\n    document.getElementById('iKTNTZ4CW42CL9R2E566E')\n  );\n</script>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_explainer = shap.KernelExplainer(model.predict, X_train_summary)\n",
    "shap_values = svm_explainer.shap_values(X_test.iloc[0,:])\n",
    "shap.force_plot(svm_explainer.expected_value, shap_values, X_test.iloc[0,:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f93d9aa9c9b84157bad143e4e035f2aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "X does not have valid feature names, but SVR was fitted with feature names\n",
      "The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LassoLarsIC())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 576x684 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm_shap_values = svm_explainer.shap_values(X_test)\n",
    "shap.summary_plot(svm_shap_values, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 540x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shap.dependence_plot(\"manganese\", svm_shap_values, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<shap.plots._force.AdditiveForceArrayVisualizer at 0x1d8a6ce7a90>",
      "text/html": "\n<div id='iWTUMCAV4SQCETPUUA61N'>\n<div style='color: #900; text-align: center;'>\n  <b>Visualization omitted, Javascript library not loaded!</b><br>\n  Have you run `initjs()` in this notebook? If this notebook was from another\n  user you must also trust this notebook (File -> Trust notebook). If you are viewing\n  this notebook on github the Javascript has been stripped for security. If you are using\n  JupyterLab this error is because a JupyterLab extension has not yet been written.\n</div></div>\n <script>\n   if (window.SHAP) SHAP.ReactDom.render(\n    SHAP.React.createElement(SHAP.AdditiveForceArrayVisualizer, {\"outNames\": [\"f(x)\"], \"baseValue\": 1.5284008825152238, \"link\": \"identity\", \"featureNames\": [\"plot_size\", \"wine_series\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"N_nitrogen\", \"N_general\", \"P_burn\", \"K_burn\", \"Mg_burn\", \"Ca_burn\", \"Na_burn\", \"B_burn\", \"chlorine\", \"iron\", \"zinc\", \"manganese\", \"copper\", \"last_four_years_mean\"], \"explanations\": [{\"outValue\": 0.9921435416093073, \"simIndex\": 32.0, \"features\": {\"0\": {\"effect\": -0.06791432671989396, \"value\": -0.7471833070360794}, \"1\": {\"effect\": 0.032139504836830035, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.055593676050328514, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10378482037889204, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.1820534092679507, \"value\": -1.5240757820298299}, \"5\": {\"effect\": -0.17424120058287085, \"value\": -0.83074430754918}, \"6\": {\"effect\": -0.05195788364727823, \"value\": -0.6124883534205269}, \"7\": {\"effect\": -0.008198577719881207, \"value\": -0.7302358547297587}, \"8\": {\"effect\": -0.050480619452767994, \"value\": -0.5090958014198733}, \"9\": {\"effect\": -0.039711802063840895, \"value\": -0.7864482792622125}, \"10\": {\"effect\": -0.0953355367526248, \"value\": -1.6089823126100216}, \"11\": {\"effect\": 0.029876969898226212, \"value\": -1.0672760476077034}, \"12\": {\"effect\": -0.00532492247799027, \"value\": -0.45334848051375276}, \"13\": {\"effect\": -0.08339064001485823, \"value\": -0.9916995666145361}, \"14\": {\"effect\": 0.0, \"value\": -0.20197130565075813}, \"15\": {\"effect\": 0.05516055589887062, \"value\": 1.126387010958939}, \"16\": {\"effect\": 0.12071132501864744, \"value\": -1.069896198751978}, \"17\": {\"effect\": -0.03003679985789192, \"value\": -1.2175397879519287}, \"18\": {\"effect\": 0.010323560501685317, \"value\": 0.2085772618764899}, \"19\": {\"effect\": 0.0, \"value\": -0.0761001326938589}, \"20\": {\"effect\": -0.013364657717349512, \"value\": -0.36584217562607535}, \"21\": {\"effect\": 0.014510571663694186, \"value\": 1.6966266872398186}, \"22\": {\"effect\": -0.5204547674137937, \"value\": -0.7419759979103228}}}, {\"outValue\": 1.9838439665327021, \"simIndex\": 3.0, \"features\": {\"0\": {\"effect\": -0.04617118962069369, \"value\": -0.5117767303048764}, \"1\": {\"effect\": -0.014031091919613187, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.05479134474161382, \"value\": -0.4470546506462881}, \"3\": {\"effect\": 0.018971569879334016, \"value\": -0.1793376441892958}, \"4\": {\"effect\": -0.04102930959818332, \"value\": 0.3440501105466866}, \"5\": {\"effect\": -0.024956689739579097, \"value\": -0.13390636051969534}, \"6\": {\"effect\": -0.05010545004805256, \"value\": -0.5993624806121547}, \"7\": {\"effect\": -0.004894696559560596, \"value\": -0.4841501018133872}, \"8\": {\"effect\": -0.05700740162709758, \"value\": -0.5816662685731596}, \"9\": {\"effect\": -0.029879379090199887, \"value\": -0.6237330338194277}, \"10\": {\"effect\": -0.012145962625367851, \"value\": -0.21425307241346336}, \"11\": {\"effect\": 0.02596099403104396, \"value\": -0.9106768660257073}, \"12\": {\"effect\": 0.015565537406248775, \"value\": 1.2501066361359519}, \"13\": {\"effect\": -0.0985178164466619, \"value\": -1.1772431461992792}, \"14\": {\"effect\": 0.0, \"value\": -1.6565453784494468}, \"15\": {\"effect\": 0.03954626516210097, \"value\": 0.8055211251804202}, \"16\": {\"effect\": 0.0, \"value\": -0.08328620751781347}, \"17\": {\"effect\": 0.0, \"value\": 0.2502001558689059}, \"18\": {\"effect\": -0.04824233371409206, \"value\": -0.9212701270083952}, \"19\": {\"effect\": -0.016059078357678308, \"value\": -0.7475892501585737}, \"20\": {\"effect\": -0.02165816195560616, \"value\": -0.6104627218567175}, \"21\": {\"effect\": 0.0, \"value\": -0.4389486748526893}, \"22\": {\"effect\": 0.765305934099523, \"value\": 1.1013739444081463}}}, {\"outValue\": 1.8167565217370374, \"simIndex\": 27.0, \"features\": {\"0\": {\"effect\": -0.022718791984006368, \"value\": -0.25021386727020634}, \"1\": {\"effect\": -0.060438061703088214, \"value\": 1.2696983622603386}, \"2\": {\"effect\": -0.03986600702763258, \"value\": 0.3965616929974163}, \"3\": {\"effect\": -0.11357902598113503, \"value\": 1.2412949376533244}, \"4\": {\"effect\": -0.11324099540449292, \"value\": 0.9383830412947989}, \"5\": {\"effect\": 0.2895487326414624, \"value\": 1.3500444155375237}, \"6\": {\"effect\": 0.0865476992985471, \"value\": 1.0653627990674475}, \"7\": {\"effect\": 0.0, \"value\": 0.18581836050143463}, \"8\": {\"effect\": 0.06380061945418938, \"value\": 0.6580266246671095}, \"9\": {\"effect\": 0.011899011201138641, \"value\": 0.1734073100164377}, \"10\": {\"effect\": -0.036635908319925456, \"value\": -0.6210491008041262}, \"11\": {\"effect\": 0.013189506204326367, \"value\": -0.4632506329342902}, \"12\": {\"effect\": 0.015836804738893782, \"value\": 1.3182448408019403}, \"13\": {\"effect\": -0.059724413440169134, \"value\": -0.7133841972374216}, \"14\": {\"effect\": 0.0, \"value\": -0.5730637599774255}, \"15\": {\"effect\": -0.041218793476607146, \"value\": -0.7988083037121746}, \"16\": {\"effect\": 0.034742551364734614, \"value\": -0.30649652578256814}, \"17\": {\"effect\": -0.010118718508324947, \"value\": -0.4246228068073399}, \"18\": {\"effect\": -0.0581981758245074, \"value\": -1.1025128743065447}, \"19\": {\"effect\": -0.013969136046140139, \"value\": -0.6422965778933964}, \"20\": {\"effect\": 0.06312989395963162, \"value\": 1.6298537807055793}, \"21\": {\"effect\": -0.003459907081036901, \"value\": -0.4527622282944261}, \"22\": {\"effect\": 0.2828287551559559, \"value\": 0.41008725224193665}}}, {\"outValue\": 1.5770123609733524, \"simIndex\": 16.0, \"features\": {\"0\": {\"effect\": 0.17160081206556843, \"value\": 1.8972172382444341}, \"1\": {\"effect\": -0.014080197370103381, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.05570794432014954, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.026846261067018554, \"value\": -0.26564108975868717}, \"4\": {\"effect\": -0.047372220822781454, \"value\": 0.3900456344169419}, \"5\": {\"effect\": 0.0433098442065894, \"value\": 0.1921438778756905}, \"6\": {\"effect\": 0.02361448133818568, \"value\": 0.30205683450280435}, \"7\": {\"effect\": 0.0035145788187092436, \"value\": 0.3508880694498695}, \"8\": {\"effect\": 0.016481332279355707, \"value\": 0.17421036348810792}, \"9\": {\"effect\": 0.037534131484920935, \"value\": 0.6507784116858425}, \"10\": {\"effect\": 0.02366746074558354, \"value\": 0.3959409701725308}, \"11\": {\"effect\": -0.017990210393627415, \"value\": 0.655314949794253}, \"12\": {\"effect\": 0.006053758618357899, \"value\": 0.4892300173657506}, \"13\": {\"effect\": -0.08216192102235378, \"value\": -0.9784464537870544}, \"14\": {\"effect\": 0.0, \"value\": 0.537504898956397}, \"15\": {\"effect\": -0.041224303823802225, \"value\": -0.7988083037121746}, \"16\": {\"effect\": 0.0026979606068275597, \"value\": -0.02213269566445675}, \"17\": {\"effect\": 0.0, \"value\": -0.002858455134686263}, \"18\": {\"effect\": -0.025245001697257463, \"value\": -0.47270514145187686}, \"19\": {\"effect\": -0.016282418749178643, \"value\": -0.7475892501585737}, \"20\": {\"effect\": 0.0048424622214217755, \"value\": 0.10581681507488128}, \"21\": {\"effect\": -0.003334999519365958, \"value\": -0.4389486748526893}, \"22\": {\"effect\": -0.11956827591608932, \"value\": -0.16719475956436716}}}, {\"outValue\": 3.4774306300815123, \"simIndex\": 1.0, \"features\": {\"0\": {\"effect\": 0.21748373563861642, \"value\": 2.396802306640654}, \"1\": {\"effect\": -0.060843765535683256, \"value\": 1.2696983622603386}, \"2\": {\"effect\": 0.05642188392304809, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.057984504848381496, \"value\": 0.6361974715371032}, \"4\": {\"effect\": 0.0, \"value\": 0.16406608752515758}, \"5\": {\"effect\": 0.13299158933784244, \"value\": 0.6131501375393374}, \"6\": {\"effect\": 0.08242167351141336, \"value\": 1.0190576366601345}, \"7\": {\"effect\": 0.0, \"value\": 0.5913215402289432}, \"8\": {\"effect\": 0.0, \"value\": -0.011988101419862144}, \"9\": {\"effect\": -0.03528305503833801, \"value\": -0.7057298297833001}, \"10\": {\"effect\": -0.08770302226690742, \"value\": -1.4927548759269753}, \"11\": {\"effect\": 0.0, \"value\": -0.3886795940857206}, \"12\": {\"effect\": 0.0, \"value\": 0.5346554871430761}, \"13\": {\"effect\": -0.08721902524623386, \"value\": -1.0447120179244627}, \"14\": {\"effect\": 0.0, \"value\": -0.05840999120321484}, \"15\": {\"effect\": 0.0, \"value\": -0.1570765321551366}, \"16\": {\"effect\": 0.06510444461193701, \"value\": -0.5674181763568922}, \"17\": {\"effect\": 0.0, \"value\": 0.41890589653796756}, \"18\": {\"effect\": -0.047775052521132844, \"value\": -0.9121863616306837}, \"19\": {\"effect\": 0.03706563246229527, \"value\": 1.6582489783910412}, \"20\": {\"effect\": 0.0, \"value\": 0.08160957352080725}, \"21\": {\"effect\": 0.0, \"value\": -0.39750801452747897}, \"22\": {\"effect\": 1.7343492135378127, \"value\": 2.4915221947008632}}}, {\"outValue\": 0.8051555261305228, \"simIndex\": 31.0, \"features\": {\"0\": {\"effect\": -0.0624306942203899, \"value\": -0.6875469742641745}, \"1\": {\"effect\": 0.0784924485053757, \"value\": -1.6164236842622004}, \"2\": {\"effect\": 0.05563686077474789, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.05559537375138606, \"value\": -0.5738676810779421}, \"4\": {\"effect\": 0.11416628340789547, \"value\": -0.9579770267036126}, \"5\": {\"effect\": -0.19953885503251928, \"value\": -0.9492541624861672}, \"6\": {\"effect\": -0.08488896253876266, \"value\": -1.0135566892318988}, \"7\": {\"effect\": -0.012048655596451241, \"value\": -1.0762939447684063}, \"8\": {\"effect\": -0.08149238235916062, \"value\": -0.8246195716515529}, \"9\": {\"effect\": -0.05027772597461547, \"value\": -0.9841354321149788}, \"10\": {\"effect\": 0.05629070195724045, \"value\": 0.9480212944170017}, \"11\": {\"effect\": 0.0, \"value\": 0.05874663900569657}, \"12\": {\"effect\": -0.017663622056982187, \"value\": -1.4981342853922381}, \"13\": {\"effect\": 0.040469548284370584, \"value\": 0.4793959572359264}, \"14\": {\"effect\": 0.0, \"value\": 0.2124604134147902}, \"15\": {\"effect\": -0.07351074038111455, \"value\": -1.4405400752692124}, \"16\": {\"effect\": 0.0, \"value\": -0.02213269566445675}, \"17\": {\"effect\": 0.10160921127245633, \"value\": 4.0460793209227885}, \"18\": {\"effect\": -0.038475459703430165, \"value\": -0.7227249694669855}, \"19\": {\"effect\": 0.015978319559605353, \"value\": 0.7311436880058333}, \"20\": {\"effect\": -0.02247152066093145, \"value\": -0.6104627218567175}, \"21\": {\"effect\": 0.0, \"value\": -0.3567580318743554}, \"22\": {\"effect\": -0.5986854853734214, \"value\": -0.8540102174689599}}}, {\"outValue\": 0.9623344944717349, \"simIndex\": 37.0, \"features\": {\"0\": {\"effect\": -0.04710340260889634, \"value\": -0.5170079875655698}, \"1\": {\"effect\": 0.0323387048854753, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.05581326813545076, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.06163026156653495, \"value\": -0.6387574897767325}, \"4\": {\"effect\": 0.02068599345205896, \"value\": -0.17959123813006414}, \"5\": {\"effect\": -0.06722311407268604, \"value\": -0.32707742406698453}, \"6\": {\"effect\": -0.0789768714903166, \"value\": -0.9406351736298312}, \"7\": {\"effect\": -0.00897895391146128, \"value\": -0.8071376525161249}, \"8\": {\"effect\": -0.027132318097376956, \"value\": -0.2724529737461136}, \"9\": {\"effect\": 0.05153908162531744, \"value\": 0.9139351666612109}, \"10\": {\"effect\": 0.12001193240614227, \"value\": 2.023125083735182}, \"11\": {\"effect\": -0.015735293855295318, \"value\": 0.5807439109456833}, \"12\": {\"effect\": -0.016772875320333794, \"value\": -1.4299960807262502}, \"13\": {\"effect\": 0.16372883975980088, \"value\": 1.9372383682589072}, \"14\": {\"effect\": 0.0, \"value\": 1.0521586677306072}, \"15\": {\"effect\": -0.041167353614080665, \"value\": -0.7988083037121746}, \"16\": {\"effect\": 0.04985236974491042, \"value\": -0.4400150266623978}, \"17\": {\"effect\": 0.0, \"value\": 0.08149441519984454}, \"18\": {\"effect\": 0.013455895945219176, \"value\": 0.26437753491100374}, \"19\": {\"effect\": 0.00962524790021882, \"value\": 0.43380777701800566}, \"20\": {\"effect\": -0.041328794313912356, \"value\": -1.1022519450079042}, \"21\": {\"effect\": 0.0, \"value\": -0.3691902299719185}, \"22\": {\"effect\": -0.8003290061802585, \"value\": -1.1439724943856844}}}, {\"outValue\": 1.6392691284882188, \"simIndex\": 19.0, \"features\": {\"0\": {\"effect\": 0.060114490575625984, \"value\": 0.6652561533511386}, \"1\": {\"effect\": -0.014088553332894452, \"value\": 0.30765768008615896}, \"2\": {\"effect\": -0.2074769794453044, \"value\": 1.9009684342043496}, \"3\": {\"effect\": -0.15723412551624055, \"value\": 1.7083717806672185}, \"4\": {\"effect\": -0.0331317864475624, \"value\": 0.2702449853210311}, \"5\": {\"effect\": 0.04908706606188222, \"value\": 0.21934188958372905}, \"6\": {\"effect\": 0.03009697753328247, \"value\": 0.3818329725714664}, \"7\": {\"effect\": 0.019262528632943955, \"value\": 1.8558562521290551}, \"8\": {\"effect\": 0.12480858070141848, \"value\": 1.2826453683119983}, \"9\": {\"effect\": 0.20245775617551795, \"value\": 3.730041162565211}, \"10\": {\"effect\": 0.11483636024864312, \"value\": 1.9359545062228973}, \"11\": {\"effect\": -0.0074521908898210615, \"value\": 0.28245975555140496}, \"12\": {\"effect\": 0.023081425908918263, \"value\": 1.9428450502401655}, \"13\": {\"effect\": 0.01811958957730414, \"value\": 0.21433370068629398}, \"14\": {\"effect\": 0.0, \"value\": -0.6001508004392261}, \"15\": {\"effect\": -0.04127050184176691, \"value\": -0.7988083037121746}, \"16\": {\"effect\": -0.3015933683889856, \"value\": 2.6716795014759334}, \"17\": {\"effect\": 0.0, \"value\": 0.08149441519984454}, \"18\": {\"effect\": -0.02532065769687561, \"value\": -0.4744353824762028}, \"19\": {\"effect\": -0.008389353530076027, \"value\": -0.3807204423918557}, \"20\": {\"effect\": 0.02836149433340597, \"value\": 0.7227192551002816}, \"21\": {\"effect\": 0.0, \"value\": -0.35744870954644226}, \"22\": {\"effect\": 0.23659949331357943, \"value\": 0.3439207377617594}}}, {\"outValue\": 1.3454466833845529, \"simIndex\": 7.0, \"features\": {\"0\": {\"effect\": -0.06461017815907823, \"value\": -0.7110876319372949}, \"1\": {\"effect\": -0.014229826585724525, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.055604336238920526, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10391176842243353, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.18209515639088858, \"value\": -1.5240757820298299}, \"5\": {\"effect\": -0.30017076555033606, \"value\": -1.423293582234116}, \"6\": {\"effect\": -0.1333663617125359, \"value\": -1.59692881404844}, \"7\": {\"effect\": -0.018484300216678018, \"value\": -1.6915083270593356}, \"8\": {\"effect\": -0.1430692301709517, \"value\": -1.455667112114912}, \"9\": {\"effect\": 0.004045171753329219, \"value\": 0.028041052583826248}, \"10\": {\"effect\": -0.017850907780222053, \"value\": -0.3014236499257483}, \"11\": {\"effect\": 0.031686035238746524, \"value\": -1.1343899825714157}, \"12\": {\"effect\": 0.010963296438913195, \"value\": 0.9207719802503423}, \"13\": {\"effect\": -0.07105033197347449, \"value\": -0.8459153255122378}, \"14\": {\"effect\": 0.0, \"value\": -1.1689786501370374}, \"15\": {\"effect\": 0.13560218349855985, \"value\": 2.730716439851534}, \"16\": {\"effect\": -0.047414617364461176, \"value\": 0.4202110400748281}, \"17\": {\"effect\": 0.021372560805593577, \"value\": 0.8406702482106212}, \"18\": {\"effect\": -0.05154159293456284, \"value\": -0.9736099179942569}, \"19\": {\"effect\": -0.018767434443260372, \"value\": -0.8548685766174335}, \"20\": {\"effect\": -0.020740425194538198, \"value\": -0.5607741734036185}, \"21\": {\"effect\": -0.004487421011425796, \"value\": -0.5632706558283205}, \"22\": {\"effect\": 0.17754868517919337, \"value\": 0.25902104676666177}}}, {\"outValue\": 1.529904280470841, \"simIndex\": 36.0, \"features\": {\"0\": {\"effect\": -0.05580451215473187, \"value\": -0.6164018755187444}, \"1\": {\"effect\": -0.01423017254480094, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.055808009204641074, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10377691962210955, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.13973958097320519, \"value\": -1.1702640599509442}, \"5\": {\"effect\": -0.17418876985219817, \"value\": -0.83074430754918}, \"6\": {\"effect\": -0.04912306148383225, \"value\": -0.576027595619493}, \"7\": {\"effect\": -0.006891840980712993, \"value\": -0.6148831580502095}, \"8\": {\"effect\": -0.03510799392918523, \"value\": -0.3513339163040335}, \"9\": {\"effect\": 0.16981964155381463, \"value\": 3.122461340356294}, \"10\": {\"effect\": 0.11300241933124644, \"value\": 1.9068976470521357}, \"11\": {\"effect\": 0.012049421080740863, \"value\": -0.4259651135100054}, \"12\": {\"effect\": 0.0, \"value\": -0.1932876660385644}, \"13\": {\"effect\": -0.020629458099401227, \"value\": -0.249525248275564}, \"14\": {\"effect\": 0.0, \"value\": 0.9438105058834049}, \"15\": {\"effect\": 0.016595667779269796, \"value\": 0.3563088850904937}, \"16\": {\"effect\": 0.07240477094640624, \"value\": -0.639783165383365}, \"17\": {\"effect\": -0.020805137773353688, \"value\": -0.8463871584799937}, \"18\": {\"effect\": 0.06659143993373548, \"value\": 1.2817592572146983}, \"19\": {\"effect\": 0.0, \"value\": -0.09066893011419781}, \"20\": {\"effect\": -0.004304960087496645, \"value\": -0.13115933908605312}, \"21\": {\"effect\": 0.0, \"value\": 0.22064850199024252}, \"22\": {\"effect\": -0.36719856556383906, \"value\": -0.522270243371584}}}, {\"outValue\": 1.0756142081087354, \"simIndex\": 40.0, \"features\": {\"0\": {\"effect\": 0.1581804030050131, \"value\": 1.7455107776843255}, \"1\": {\"effect\": -0.014090212493289567, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.055591939717602734, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.06550870999522033, \"value\": 0.7239284928978679}, \"4\": {\"effect\": -0.2252559424480467, \"value\": 1.8725167499274729}, \"5\": {\"effect\": 0.17877768780282838, \"value\": 0.8283936615686405}, \"6\": {\"effect\": 0.0717873396013955, \"value\": 0.8824027164218596}, \"7\": {\"effect\": 0.0, \"value\": 0.6155456065316487}, \"8\": {\"effect\": -0.007884765129464871, \"value\": -0.07525061735131387}, \"9\": {\"effect\": 0.05615038275248521, \"value\": 0.9983973451317922}, \"10\": {\"effect\": 0.07729953073440315, \"value\": 1.2967036044661415}, \"11\": {\"effect\": -0.013650239269884124, \"value\": 0.5061728720971137}, \"12\": {\"effect\": 0.0, \"value\": -0.11265745718381202}, \"13\": {\"effect\": 0.19172044866869126, \"value\": 2.2685661889459485}, \"14\": {\"effect\": 0.0, \"value\": 1.079245708192407}, \"15\": {\"effect\": -0.05740901117505748, \"value\": -1.1196741894906934}, \"16\": {\"effect\": 0.03306443660297134, \"value\": -0.2912081478192282}, \"17\": {\"effect\": 0.0, \"value\": -0.08721132546921707}, \"18\": {\"effect\": -0.01443553588241231, \"value\": -0.27632278519087466}, \"19\": {\"effect\": -0.01770814197159687, \"value\": -0.8290420720995598}, \"20\": {\"effect\": -0.026555232786502292, \"value\": -0.7284411727992043}, \"21\": {\"effect\": 0.0, \"value\": -0.20619029935942443}, \"22\": {\"effect\": -0.8328610521404045, \"value\": -1.19031471114255}}}, {\"outValue\": 0.901153665831345, \"simIndex\": 39.0, \"features\": {\"0\": {\"effect\": 0.15771274270087993, \"value\": 1.7455107776843255}, \"1\": {\"effect\": -0.014168472933887483, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.05586762709523875, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.0658730328133602, \"value\": 0.7239284928978679}, \"4\": {\"effect\": -0.2253172964487662, \"value\": 1.8725167499274729}, \"5\": {\"effect\": 0.1783569964215219, \"value\": 0.8283936615686405}, \"6\": {\"effect\": 0.07146264478187532, \"value\": 0.8824027164218596}, \"7\": {\"effect\": 0.0, \"value\": 0.6155456065316487}, \"8\": {\"effect\": -0.008100699106344533, \"value\": -0.07525061735131387}, \"9\": {\"effect\": 0.0356658976548688, \"value\": 0.6099626346303293}, \"10\": {\"effect\": 0.04625220870594411, \"value\": 0.7736801393924324}, \"11\": {\"effect\": -0.018063502650769336, \"value\": 0.655314949794253}, \"12\": {\"effect\": 0.0, \"value\": -0.4079230107364273}, \"13\": {\"effect\": 0.04650423942603715, \"value\": 0.5456615213733347}, \"14\": {\"effect\": 0.0, \"value\": 0.6458530608035993}, \"15\": {\"effect\": -0.05748342619403328, \"value\": -1.1196741894906934}, \"16\": {\"effect\": 0.02397454349850689, \"value\": -0.21170858240986434}, \"17\": {\"effect\": 0.018869627308596315, \"value\": 0.7563173778760903}, \"18\": {\"effect\": 0.0, \"value\": 0.007004182542509788}, \"19\": {\"effect\": -0.019990737789028767, \"value\": -0.9409569250103454}, \"20\": {\"effect\": -0.01971482701654645, \"value\": -0.546249828471174}, \"21\": {\"effect\": 0.0, \"value\": -0.28561823164941097}, \"22\": {\"effect\": -0.8332017493246117, \"value\": -1.19031471114255}}}, {\"outValue\": 1.2211850950117924, \"simIndex\": 9.0, \"features\": {\"0\": {\"effect\": -0.04644206058433871, \"value\": -0.5117767303048764}, \"1\": {\"effect\": 0.07855778296774302, \"value\": -1.6164236842622004}, \"2\": {\"effect\": 0.055744787333044235, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.1039792316052003, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.1821723585043714, \"value\": -1.5240757820298299}, \"5\": {\"effect\": -0.3000789898186845, \"value\": -1.423293582234116}, \"6\": {\"effect\": -0.13308258163006126, \"value\": -1.59692881404844}, \"7\": {\"effect\": -0.011709678344959229, \"value\": -1.0762939447684063}, \"8\": {\"effect\": -0.08127092906495158, \"value\": -0.8246195716515529}, \"9\": {\"effect\": -0.05065749874412648, \"value\": -0.9949100667739286}, \"10\": {\"effect\": -0.034841869192407254, \"value\": -0.5919922416333646}, \"11\": {\"effect\": -0.0324858273889832, \"value\": 1.1773122217342393}, \"12\": {\"effect\": -0.00933449762771621, \"value\": -0.8053958712880251}, \"13\": {\"effect\": 0.0071701691031321735, \"value\": 0.08180257241147743}, \"14\": {\"effect\": 0.0, \"value\": 0.9167234654216049}, \"15\": {\"effect\": -0.04124526757279276, \"value\": -0.7988083037121746}, \"16\": {\"effect\": 0.043662768322646726, \"value\": -0.38497686599437625}, \"17\": {\"effect\": -0.012212415539489346, \"value\": -0.5089756771418706}, \"18\": {\"effect\": 0.10270192732179283, \"value\": 1.9703951848964505}, \"19\": {\"effect\": 0.012388848278678033, \"value\": 0.5616158634782522}, \"20\": {\"effect\": -0.020396576622428608, \"value\": -0.5538942205408816}, \"21\": {\"effect\": -0.004695085503436919, \"value\": -0.6040206384814439}, \"22\": {\"effect\": -0.11514038330566415, \"value\": -0.16078810893660986}}}, {\"outValue\": 1.384803300463028, \"simIndex\": 10.0, \"features\": {\"0\": {\"effect\": -0.0938617091852482, \"value\": -1.0349024563742164}, \"1\": {\"effect\": 0.07846555866375768, \"value\": -1.6164236842622004}, \"2\": {\"effect\": 0.05567246648991054, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.1039041446567299, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.18214250624361067, \"value\": -1.5240757820298299}, \"5\": {\"effect\": -0.19938058902466851, \"value\": -0.9492541624861672}, \"6\": {\"effect\": -0.07295911437740535, \"value\": -0.8677136580277636}, \"7\": {\"effect\": -0.008504319215433126, \"value\": -0.7686867536229418}, \"8\": {\"effect\": -0.05046956996751317, \"value\": -0.5090958014198733}, \"9\": {\"effect\": -0.05043056285659908, \"value\": -0.9885183343491277}, \"10\": {\"effect\": -0.024603065700308353, \"value\": -0.41765108660879496}, \"11\": {\"effect\": 0.023458025432503922, \"value\": -0.8361058271771378}, \"12\": {\"effect\": -0.01533663452192067, \"value\": -1.3050760388386051}, \"13\": {\"effect\": -0.043113928619398514, \"value\": -0.5145875048251968}, \"14\": {\"effect\": 0.0, \"value\": -0.19384519351221766}, \"15\": {\"effect\": -0.057369540060803734, \"value\": -1.1196741894906934}, \"16\": {\"effect\": 0.12700466753295978, \"value\": -1.1239151342224436}, \"17\": {\"effect\": -0.020715904878525104, \"value\": -0.8463871584799937}, \"18\": {\"effect\": 0.030998929915675596, \"value\": 0.601774534654576}, \"19\": {\"effect\": 0.041096916385812615, \"value\": 1.8734698493733213}, \"20\": {\"effect\": -0.026948754965864102, \"value\": -0.7235997244883894}, \"21\": {\"effect\": -0.0045501318506292205, \"value\": -0.5770842092700572}, \"22\": {\"effect\": -0.11809697214883934, \"value\": -0.16498742615480394}}}, {\"outValue\": 1.4239007475548906, \"simIndex\": 21.0, \"features\": {\"0\": {\"effect\": -0.03230851315074827, \"value\": -0.35483901248407435}, \"1\": {\"effect\": -0.014179896344213988, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.05567653522101564, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.0035469486351357715, \"value\": -0.01646422435533166}, \"4\": {\"effect\": -0.04329835633505584, \"value\": 0.3551951797921717}, \"5\": {\"effect\": 0.13704146623068342, \"value\": 0.633148675559954}, \"6\": {\"effect\": -0.0646540913451184, \"value\": -0.7673007310437164}, \"7\": {\"effect\": -0.006355886278630721, \"value\": -0.5669733380293035}, \"8\": {\"effect\": -0.10515749593411719, \"value\": -1.067730636615062}, \"9\": {\"effect\": 0.016002908842016855, \"value\": 0.2507472723565269}, \"10\": {\"effect\": -0.003946218955244718, \"value\": -0.06896877655965507}, \"11\": {\"effect\": -0.04713194721762318, \"value\": 1.6993094936742263}, \"12\": {\"effect\": 0.002132209873214927, \"value\": 0.1712517289244721}, \"13\": {\"effect\": 0.0015644526882773457, \"value\": 0.015537008274069135}, \"14\": {\"effect\": 0.0, \"value\": -0.27510631489761933}, \"15\": {\"effect\": 0.006972602200467512, \"value\": 0.16378935362338218}, \"16\": {\"effect\": -0.10230567315927135, \"value\": 0.9074006845065747}, \"17\": {\"effect\": 0.02562016760177735, \"value\": 1.0093759888796827}, \"18\": {\"effect\": -0.040219432831478275, \"value\": -0.7581949104656686}, \"19\": {\"effect\": 0.005000497168835591, \"value\": 0.22653352281045544}, \"20\": {\"effect\": 0.051346633655354336, \"value\": 1.3220395933653548}, \"21\": {\"effect\": -0.0035285465785834524, \"value\": -0.453452905966513}, \"22\": {\"effect\": 0.05368150105297348, \"value\": 0.0813991991912734}}}, {\"outValue\": 1.7410479681110798, \"simIndex\": 23.0, \"features\": {\"0\": {\"effect\": -0.03706433445235695, \"value\": -0.40715158509100835}, \"1\": {\"effect\": 0.03212732188656407, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.05567611653045181, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.06983108795431597, \"value\": 0.7709087143957922}, \"4\": {\"effect\": -0.07253280314696772, \"value\": 0.5987945504434844}, \"5\": {\"effect\": 0.13440415297105276, \"value\": 0.621001415428913}, \"6\": {\"effect\": 0.03510244317675075, \"value\": 0.44235783052118244}, \"7\": {\"effect\": 0.004559037753884006, \"value\": 0.4617420109589164}, \"8\": {\"effect\": 0.0266977832192822, \"value\": 0.27971362415932566}, \"9\": {\"effect\": 0.08326353465382715, \"value\": 1.5058095891977605}, \"10\": {\"effect\": 0.0476544684608618, \"value\": 0.8027369985631934}, \"11\": {\"effect\": -0.04507263158101637, \"value\": 1.624738454825657}, \"12\": {\"effect\": 0.0, \"value\": -0.10130108973948039}, \"13\": {\"effect\": 0.11884519289753176, \"value\": 1.4071138551596416}, \"14\": {\"effect\": 0.0, \"value\": -0.004235910279613714}, \"15\": {\"effect\": -0.041323206326719875, \"value\": -0.7988083037121746}, \"16\": {\"effect\": -0.14788311376567115, \"value\": 1.311013862738733}, \"17\": {\"effect\": -0.006018631318459054, \"value\": -0.25591706613827847}, \"18\": {\"effect\": -0.04117848870189446, \"value\": -0.7759298809650101}, \"19\": {\"effect\": -0.008359277434952874, \"value\": -0.3807204423918557}, \"20\": {\"effect\": 0.04774450218766334, \"value\": 1.2295424493218932}, \"21\": {\"effect\": -0.0031093725424111707, \"value\": -0.3981986921995658}, \"22\": {\"effect\": 0.09894547908275195, \"value\": 0.14643999418820458}}}, {\"outValue\": 1.9517220279861311, \"simIndex\": 6.0, \"features\": {\"0\": {\"effect\": 0.0267254154053565, \"value\": 0.2982834565134966}, \"1\": {\"effect\": -0.06055022814248312, \"value\": 1.2696983622603386}, \"2\": {\"effect\": -0.42673302957168585, \"value\": 3.866256486803018}, \"3\": {\"effect\": -0.17361976783721186, \"value\": 1.8823413577886756}, \"4\": {\"effect\": -0.1591729506012836, \"value\": 1.3195090283181747}, \"5\": {\"effect\": 0.18221721158069293, \"value\": 0.8470589637212158}, \"6\": {\"effect\": 0.15276427147233784, \"value\": 1.869541273127049}, \"7\": {\"effect\": 0.018778388393217993, \"value\": 1.809676722558342}, \"8\": {\"effect\": 0.19416682957391854, \"value\": 1.9924555299194404}, \"9\": {\"effect\": -0.044134220309487826, \"value\": -0.8687190066157193}, \"10\": {\"effect\": -0.03841908280369756, \"value\": -0.6501059599748878}, \"11\": {\"effect\": 0.021193913634645428, \"value\": -0.7615347883285681}, \"12\": {\"effect\": 0.016562037291532494, \"value\": 1.409095780356591}, \"13\": {\"effect\": -0.06559918206638735, \"value\": -0.7796497613748299}, \"14\": {\"effect\": 0.0, \"value\": -0.6001508004392261}, \"15\": {\"effect\": 0.03902992913549114, \"value\": 0.8055211251804202}, \"16\": {\"effect\": -0.07523128581470417, \"value\": 0.6668635378833694}, \"17\": {\"effect\": 0.01698119450282673, \"value\": 0.6719645075415596}, \"18\": {\"effect\": -0.02829547093668186, \"value\": -0.5250449324377388}, \"19\": {\"effect\": 0.009414283480553592, \"value\": 0.43910552153449245}, \"20\": {\"effect\": 0.0050867842907585115, \"value\": 0.11524489862752073}, \"21\": {\"effect\": 0.0, \"value\": -0.42582579908303936}, \"22\": {\"effect\": 0.8121561047931989, \"value\": 1.1697472414054761}}}, {\"outValue\": 1.1590552678362989, \"simIndex\": 29.0, \"features\": {\"0\": {\"effect\": -0.04082383310113019, \"value\": -0.4513557089438676}, \"1\": {\"effect\": -0.014103874353744512, \"value\": 0.30765768008615896}, \"2\": {\"effect\": -0.03767240506201431, \"value\": 0.3816593793009957}, \"3\": {\"effect\": 0.06542665592174682, \"value\": -0.6776913749960067}, \"4\": {\"effect\": 0.0, \"value\": -0.012592105308830122}, \"5\": {\"effect\": -0.020085448309787222, \"value\": -0.10664909388418845}, \"6\": {\"effect\": 0.030794442550518435, \"value\": 0.3850779800157584}, \"7\": {\"effect\": 0.008890106269379507, \"value\": 0.8324086762892012}, \"8\": {\"effect\": 0.20314926557150362, \"value\": 2.078199114479899}, \"9\": {\"effect\": 0.022902499772591844, \"value\": 0.3672594234143234}, \"10\": {\"effect\": -0.01554703471867706, \"value\": -0.27236679075498665}, \"11\": {\"effect\": 0.061058672753211966, \"value\": -2.178384526451389}, \"12\": {\"effect\": 0.0, \"value\": 0.31888450570078025}, \"13\": {\"effect\": 0.012925236884432159, \"value\": 0.1480681365488857}, \"14\": {\"effect\": 0.0, \"value\": -0.8710212050572311}, \"15\": {\"effect\": -0.040884651406722615, \"value\": -0.7988083037121746}, \"16\": {\"effect\": -0.09886586930413721, \"value\": 0.8798816041725637}, \"17\": {\"effect\": 0.0, \"value\": 0.08149441519984454}, \"18\": {\"effect\": -0.03595468086218384, \"value\": -0.6824968656514055}, \"19\": {\"effect\": -0.02365668250895719, \"value\": -1.093929297923905}, \"20\": {\"effect\": -0.020135637689441377, \"value\": -0.5572067904377549}, \"21\": {\"effect\": -0.004356236657696501, \"value\": -0.6054019938256177}, \"22\": {\"effect\": -0.4224061404278172, \"value\": -0.602003467807564}}}, {\"outValue\": 1.2719084418821873, \"simIndex\": 8.0, \"features\": {\"0\": {\"effect\": -0.05832723221959205, \"value\": -0.6425581618222114}, \"1\": {\"effect\": 0.032176998485393474, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.05570028428155677, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10391980537351564, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.1821590358638687, \"value\": -1.5240757820298299}, \"5\": {\"effect\": -0.30015266238284355, \"value\": -1.423293582234116}, \"6\": {\"effect\": -0.1330905153187132, \"value\": -1.59692881404844}, \"7\": {\"effect\": -0.01836678872852794, \"value\": -1.6915083270593356}, \"8\": {\"effect\": -0.06589469474344868, \"value\": -0.6668576865357131}, \"9\": {\"effect\": -0.04105028720911218, \"value\": -0.8139327286888557}, \"10\": {\"effect\": -0.022863364550759088, \"value\": -0.3885942274380333}, \"11\": {\"effect\": -0.012439254001998488, \"value\": 0.453973144903115}, \"12\": {\"effect\": -0.021792776470084138, \"value\": -1.852452949655377}, \"13\": {\"effect\": -0.07102226928006813, \"value\": -0.8459153255122378}, \"14\": {\"effect\": 0.0, \"value\": 0.15828633249118906}, \"15\": {\"effect\": 0.03917627862396244, \"value\": 0.8055211251804202}, \"16\": {\"effect\": 0.14601485203037706, \"value\": -1.2920872918191766}, \"17\": {\"effect\": -0.02279551556054367, \"value\": -0.9307400288145243}, \"18\": {\"effect\": 0.10609013654320643, \"value\": 2.035279223308676}, \"19\": {\"effect\": 0.007392085916543334, \"value\": 0.3344750673338763}, \"20\": {\"effect\": -0.03219152349298872, \"value\": -0.8614535948121158}, \"21\": {\"effect\": 0.026879419228541694, \"value\": 3.1815836822265235}, \"22\": {\"effect\": -0.15601445302132222, \"value\": -0.21940841955066476}}}, {\"outValue\": 1.873911417933861, \"simIndex\": 24.0, \"features\": {\"0\": {\"effect\": -0.05834546977583521, \"value\": -0.6425581618222114}, \"1\": {\"effect\": -0.014199970863184821, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.055833786521527, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.014476234065648463, \"value\": 0.17723185461055793}, \"4\": {\"effect\": -0.049651294146939834, \"value\": 0.40791312638192545}, \"5\": {\"effect\": 0.24795315949820562, \"value\": 1.1542957626453552}, \"6\": {\"effect\": 0.045928617453352, \"value\": 0.5724862751130723}, \"7\": {\"effect\": 0.005896143636213436, \"value\": 0.5722498943779246}, \"8\": {\"effect\": 0.09433866417765478, \"value\": 0.9704345976677512}, \"9\": {\"effect\": 0.0, \"value\": -0.08436212762945548}, \"10\": {\"effect\": -0.026178999405614953, \"value\": -0.44670794577955664}, \"11\": {\"effect\": -0.017331075668912718, \"value\": 0.632943638139682}, \"12\": {\"effect\": 0.0, \"value\": 0.1258262591471466}, \"13\": {\"effect\": 0.0, \"value\": 0.015537008274069135}, \"14\": {\"effect\": 0.0, \"value\": -0.545976719515625}, \"15\": {\"effect\": 0.04072977009056469, \"value\": 0.837607713758272}, \"16\": {\"effect\": -0.07033479350718401, \"value\": 0.6240560795860192}, \"17\": {\"effect\": 0.027857962528458513, \"value\": 1.0937288592142131}, \"18\": {\"effect\": 0.014486063983899039, \"value\": 0.28643810797116026}, \"19\": {\"effect\": 0.009819886884216922, \"value\": 0.44175439379273584}, \"20\": {\"effect\": -0.01805616129554019, \"value\": -0.4907005794312991}, \"21\": {\"effect\": 0.004402267256476924, \"value\": 0.49208482712037044}, \"22\": {\"effect\": 0.06683821211692847, \"value\": 0.10023763178520871}}}, {\"outValue\": 0.6356882319045647, \"simIndex\": 30.0, \"features\": {\"0\": {\"effect\": -0.05019704942443737, \"value\": -0.5525805369382848}, \"1\": {\"effect\": 0.03207107442636825, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.0556050209262684, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.05547164997407464, \"value\": -0.5738676810779421}, \"4\": {\"effect\": 0.1141599047403267, \"value\": -0.9579770267036126}, \"5\": {\"effect\": -0.14906908893735055, \"value\": -0.7122344526121929}, \"6\": {\"effect\": -0.06095850981319345, \"value\": -0.7218706268236283}, \"7\": {\"effect\": -0.008628429477674393, \"value\": -0.7686867536229418}, \"8\": {\"effect\": -0.05053074325729284, \"value\": -0.5090958014198733}, \"9\": {\"effect\": -0.041913567916315286, \"value\": -0.8289076446555318}, \"10\": {\"effect\": 0.03389751898454835, \"value\": 0.5702821251971008}, \"11\": {\"effect\": -0.024339527779758008, \"value\": 0.8790280663399617}, \"12\": {\"effect\": -0.004900171486396543, \"value\": -0.4192793781807589}, \"13\": {\"effect\": -0.0598667637417411, \"value\": -0.7133841972374216}, \"14\": {\"effect\": 0.0, \"value\": 0.37498265618559357}, \"15\": {\"effect\": -0.05744017369760107, \"value\": -1.1196741894906934}, \"16\": {\"effect\": -0.2624966508562497, \"value\": 2.3271813847020195}, \"17\": {\"effect\": -0.02279071707755831, \"value\": -0.9307400288145243}, \"18\": {\"effect\": -0.03259448468493231, \"value\": -0.6119895439101207}, \"19\": {\"effect\": 0.026939045288769448, \"value\": 1.228469454491041}, \"20\": {\"effect\": -0.027321404280985062, \"value\": -0.7335374341790092}, \"21\": {\"effect\": 0.0, \"value\": -0.21931317512907433}, \"22\": {\"effect\": -0.3578095825195289, \"value\": -0.5087666214118555}}}, {\"outValue\": 2.6744467742580884, \"simIndex\": 5.0, \"features\": {\"0\": {\"effect\": 0.03463425856567748, \"value\": 0.4201717506876529}, \"1\": {\"effect\": -0.06400829623471829, \"value\": 1.2696983622603386}, \"2\": {\"effect\": 0.0, \"value\": 0.1744808718141748}, \"3\": {\"effect\": -0.06231102986697423, \"value\": 0.6557941937641378}, \"4\": {\"effect\": -0.10812673667666339, \"value\": 0.8676914592234374}, \"5\": {\"effect\": 0.2905411420780334, \"value\": 1.3690948747186444}, \"6\": {\"effect\": 0.03061936785881511, \"value\": 0.4175280544586785}, \"7\": {\"effect\": 0.0, \"value\": -0.17973433527605673}, \"8\": {\"effect\": 0.0, \"value\": 0.025993072421776325}, \"9\": {\"effect\": 0.0, \"value\": 0.1347829840779989}, \"10\": {\"effect\": 0.0, \"value\": -0.11255406531579787}, \"11\": {\"effect\": 0.036473320538900844, \"value\": -1.4140313782535516}, \"12\": {\"effect\": 0.0, \"value\": -1.6378176049575144}, \"13\": {\"effect\": 0.1188556422531834, \"value\": 1.4402466372283458}, \"14\": {\"effect\": 0.0, \"value\": -1.2366962512915385}, \"15\": {\"effect\": 0.010544498535098035, \"value\": 0.3081790022237158}, \"16\": {\"effect\": 0.13624909919996775, \"value\": -1.2411260319413788}, \"17\": {\"effect\": 0.0, \"value\": -0.5511521123091361}, \"18\": {\"effect\": 0.011179316661147715, \"value\": 0.3082824009032766}, \"19\": {\"effect\": 0.0, \"value\": 0.13183633957825208}, \"20\": {\"effect\": 0.0, \"value\": 0.030392146653766626}, \"21\": {\"effect\": 0.015016884538339048, \"value\": 2.0754633903794506}, \"22\": {\"effect\": 0.6963784242920578, \"value\": 1.0062765893855135}}}, {\"outValue\": 1.9853350575548125, \"simIndex\": 28.0, \"features\": {\"0\": {\"effect\": -0.030735294376888732, \"value\": -0.32842116331757276}, \"1\": {\"effect\": -0.061185815699515006, \"value\": 1.2696983622603386}, \"2\": {\"effect\": 0.05494209341478509, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.12824614586334346, \"value\": 1.3890490320604705}, \"4\": {\"effect\": -0.21406767836329177, \"value\": 1.7707958798297934}, \"5\": {\"effect\": 0.1785470387153956, \"value\": 0.8302305643201637}, \"6\": {\"effect\": 0.10985934271426967, \"value\": 1.3586531348189632}, \"7\": {\"effect\": 0.016783357950124526, \"value\": 1.6152689777544085}, \"8\": {\"effect\": 0.08813365575442562, \"value\": 0.9169138781422026}, \"9\": {\"effect\": 0.0, \"value\": -0.14042675204127922}, \"10\": {\"effect\": -0.013054293154037007, \"value\": -0.21425307241346336}, \"11\": {\"effect\": 0.00975544718511729, \"value\": -0.3886795940857206}, \"12\": {\"effect\": 0.011264514086412436, \"value\": 1.0116229198049933}, \"13\": {\"effect\": -0.07736958662690496, \"value\": -0.9121808896496462}, \"14\": {\"effect\": 0.0, \"value\": -1.0877175287516356}, \"15\": {\"effect\": 0.05396738575494478, \"value\": 1.126387010958939}, \"16\": {\"effect\": -0.035280988806816654, \"value\": 0.3060578179485614}, \"17\": {\"effect\": 0.014533818014180702, \"value\": 0.5876116372070287}, \"18\": {\"effect\": -0.04930297249495826, \"value\": -0.9208375667523137}, \"19\": {\"effect\": 0.0, \"value\": -0.21847701657444432}, \"20\": {\"effect\": 0.005098740237726534, \"value\": 0.1371588225606824}, \"21\": {\"effect\": 0.0, \"value\": -0.4942028886196365}, \"22\": {\"effect\": 0.5232915565979623, \"value\": 0.7561014577666861}}}, {\"outValue\": 1.6751431004736526, \"simIndex\": 13.0, \"features\": {\"0\": {\"effect\": -0.04644159714446962, \"value\": -0.5117767303048764}, \"1\": {\"effect\": 0.032179544307767816, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.05573629484057002, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.09597232130258453, \"value\": -1.0073316031858626}, \"4\": {\"effect\": 0.17711841163508152, \"value\": -1.4816183753803633}, \"5\": {\"effect\": -0.09344364447785708, \"value\": -0.45151277175082116}, \"6\": {\"effect\": -0.03973142703354554, \"value\": -0.4666453222163916}, \"7\": {\"effect\": -0.008516152276453387, \"value\": -0.7686867536229418}, \"8\": {\"effect\": -0.01536472795981203, \"value\": -0.15097632220691704}, \"9\": {\"effect\": 0.0945525462783692, \"value\": 1.7145453080991107}, \"10\": {\"effect\": 0.03565632233005711, \"value\": 0.5993389843678624}, \"11\": {\"effect\": -0.011774965835099432, \"value\": 0.4316018332485441}, \"12\": {\"effect\": -0.00557347335835906, \"value\": -0.48741758284674713}, \"13\": {\"effect\": 0.09660231740079651, \"value\": 1.1420515986100086}, \"14\": {\"effect\": 0.0, \"value\": 1.0250716272688072}, \"15\": {\"effect\": -0.05731072282063834, \"value\": -1.1196741894906934}, \"16\": {\"effect\": -0.04437546641457979, \"value\": 0.395749635333485}, \"17\": {\"effect\": -0.014343022813453843, \"value\": -0.5933285474764015}, \"18\": {\"effect\": -0.02262382271040217, \"value\": -0.42339327225858553}, \"19\": {\"effect\": -0.0131288275864056, \"value\": -0.6058745843425489}, \"20\": {\"effect\": 0.052754521389537345, \"value\": 1.3551652923340876}, \"21\": {\"effect\": -0.00319730794914197, \"value\": -0.4265164767551262}, \"22\": {\"effect\": -0.11800490314611733, \"value\": -0.16496833834926658}}}, {\"outValue\": 0.9217447016907752, \"simIndex\": 33.0, \"features\": {\"0\": {\"effect\": -0.07521314151488254, \"value\": -0.8295756088920003}, \"1\": {\"effect\": 0.07851785824443802, \"value\": -1.6164236842622004}, \"2\": {\"effect\": 0.05572515014678502, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10395961083352012, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.15245693751531278, \"value\": -1.27640757657461}, \"5\": {\"effect\": -0.3001377851587543, \"value\": -1.423293582234116}, \"6\": {\"effect\": -0.1119987360576336, \"value\": -1.3417035094412033}, \"7\": {\"effect\": -0.012197390553906895, \"value\": -1.1147448436615894}, \"8\": {\"effect\": -0.08904629833996949, \"value\": -0.9035005142094729}, \"9\": {\"effect\": 0.02487860231763667, \"value\": 0.4147408642842718}, \"10\": {\"effect\": -0.01761572574855117, \"value\": -0.3014236499257483}, \"11\": {\"effect\": 0.0077515039562049, \"value\": -0.26936593192800923}, \"12\": {\"effect\": 0.0049267906667953484, \"value\": 0.4063285350221317}, \"13\": {\"effect\": 0.025652640071685936, \"value\": 0.30047893406492404}, \"14\": {\"effect\": 0.0, \"value\": 0.1068209556137683}, \"15\": {\"effect\": 0.015119927389549814, \"value\": 0.3242222965126418}, \"16\": {\"effect\": 0.06343171552110151, \"value\": -0.5602835999740005}, \"17\": {\"effect\": -0.022744744815940868, \"value\": -0.9307400288145243}, \"18\": {\"effect\": 0.04131372460201394, \"value\": 0.7981568909155782}, \"19\": {\"effect\": -0.020179329407307905, \"value\": -0.9257259095254459}, \"20\": {\"effect\": 0.0, \"value\": -0.027195606938030307}, \"21\": {\"effect\": 0.0, \"value\": 0.08251296757287449}, \"22\": {\"effect\": -0.531257490492546, \"value\": -0.757782622673248}}}, {\"outValue\": 1.8851951493369523, \"simIndex\": 14.0, \"features\": {\"0\": {\"effect\": -0.03479792637423321, \"value\": -0.3836109274178881}, \"1\": {\"effect\": 0.03217469378883417, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.05580521624348711, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.08488116815811964, \"value\": -0.8881939144148832}, \"4\": {\"effect\": 0.12837501781777022, \"value\": -1.0751594690561395}, \"5\": {\"effect\": -0.10211768360543962, \"value\": -0.49186537735686525}, \"6\": {\"effect\": -0.005197248205653815, \"value\": -0.04734660750450268}, \"7\": {\"effect\": 0.0, \"value\": 0.13729332609823758}, \"8\": {\"effect\": -0.012555186353478132, \"value\": -0.12210589723071838}, \"9\": {\"effect\": 0.012930421248737445, \"value\": 0.19331299099653143}, \"10\": {\"effect\": 0.009934317817343497, \"value\": 0.16348609680643755}, \"11\": {\"effect\": -0.034615352967013485, \"value\": 1.251883260582809}, \"12\": {\"effect\": -0.008734399112909796, \"value\": -0.7486140340663683}, \"13\": {\"effect\": 0.05735366545364043, \"value\": 0.6781926496481513}, \"14\": {\"effect\": 0.0, \"value\": -0.7626730432100289}, \"15\": {\"effect\": -0.04124163796558386, \"value\": -0.7988083037121746}, \"16\": {\"effect\": 0.04467121891982134, \"value\": -0.3941498927723802}, \"17\": {\"effect\": 0.0, \"value\": -0.002858455134686263}, \"18\": {\"effect\": -0.019080918097955896, \"value\": -0.35418363128554503}, \"19\": {\"effect\": -0.022423991084867992, \"value\": -1.0270452734032578}, \"20\": {\"effect\": 0.15107284549415012, \"value\": 3.927248410721693}, \"21\": {\"effect\": -0.0034913248726693435, \"value\": -0.453452905966513}, \"22\": {\"effect\": 0.06385137051962969, \"value\": 0.09599203142649837}}}, {\"outValue\": 2.92232815887553, \"simIndex\": 2.0, \"features\": {\"0\": {\"effect\": 0.09955464133459907, \"value\": 1.1099130205100776}, \"1\": {\"effect\": -0.06068224637246439, \"value\": 1.2696983622603386}, \"2\": {\"effect\": 0.05367368767317392, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.05179429881732081, \"value\": 0.5563830068375908}, \"4\": {\"effect\": 0.0, \"value\": 0.0995662105901767}, \"5\": {\"effect\": 0.1499951061792111, \"value\": 0.6969069775160531}, \"6\": {\"effect\": 0.0, \"value\": 0.24401130808355853}, \"7\": {\"effect\": 0.0, \"value\": 0.36261559361229034}, \"8\": {\"effect\": 0.0, \"value\": 0.17511749432752385}, \"9\": {\"effect\": 0.0, \"value\": 0.030323814164112232}, \"10\": {\"effect\": -0.05116045932829054, \"value\": -0.8535039741702192}, \"11\": {\"effect\": 0.0, \"value\": -0.015824399842873028}, \"12\": {\"effect\": 0.0, \"value\": 0.56872458947607}, \"13\": {\"effect\": -0.10507326805224729, \"value\": -1.243508710336687}, \"14\": {\"effect\": 0.0, \"value\": -1.006456407366234}, \"15\": {\"effect\": 0.0, \"value\": -0.1570765321551366}, \"16\": {\"effect\": 0.0, \"value\": 0.13278953436404875}, \"17\": {\"effect\": 0.021106149316212644, \"value\": 0.8406702482106212}, \"18\": {\"effect\": 0.0, \"value\": -0.19932705960836714}, \"19\": {\"effect\": 0.030330397960845433, \"value\": 1.3715085564361877}, \"20\": {\"effect\": 0.0, \"value\": -0.16071765508892247}, \"21\": {\"effect\": 0.0, \"value\": -0.453452905966513}, \"22\": {\"effect\": 1.307977566466587, \"value\": 1.8808742873359732}}}, {\"outValue\": 2.052520047065186, \"simIndex\": 25.0, \"features\": {\"0\": {\"effect\": -0.030812286101232933, \"value\": -0.33914524070199403}, \"1\": {\"effect\": -0.060486457696670375, \"value\": 1.2696983622603386}, \"2\": {\"effect\": 0.05577915471328447, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.05777679805568417, \"value\": 0.6417131052765004}, \"4\": {\"effect\": -0.17731967820888556, \"value\": 1.4727095039783322}, \"5\": {\"effect\": 0.23776202029012122, \"value\": 1.1068918206705605}, \"6\": {\"effect\": 0.08208558259542653, \"value\": 1.010015368725478}, \"7\": {\"effect\": 0.004410344000009378, \"value\": 0.43609526139716326}, \"8\": {\"effect\": 0.0, \"value\": 0.016764002142499627}, \"9\": {\"effect\": -0.03287392607160736, \"value\": -0.661444255125752}, \"10\": {\"effect\": -0.08657924469960895, \"value\": -1.4636980167562137}, \"11\": {\"effect\": 0.03870260896403935, \"value\": -1.3804744107716953}, \"12\": {\"effect\": -0.006805016559212423, \"value\": -0.5941674368234618}, \"13\": {\"effect\": 0.06303571704137603, \"value\": 0.7444582137855595}, \"14\": {\"effect\": 0.0, \"value\": -0.22093223397401823}, \"15\": {\"effect\": 0.0439857020703682, \"value\": 0.901780890913976}, \"16\": {\"effect\": 0.0494086421760333, \"value\": -0.435938125872174}, \"17\": {\"effect\": 0.0067255679882681635, \"value\": 0.2502001558689059}, \"18\": {\"effect\": 0.0625294132918116, \"value\": 1.2034658508639462}, \"19\": {\"effect\": -0.010248599063756164, \"value\": -0.4721065353012547}, \"20\": {\"effect\": -0.009364033304524233, \"value\": -0.2657006395129063}, \"21\": {\"effect\": 0.02928247351701889, \"value\": 3.4668335607983884}, \"22\": {\"effect\": 0.3226779776633872, \"value\": 0.4671994851497764}}}, {\"outValue\": 0.6522257548337672, \"simIndex\": 34.0, \"features\": {\"0\": {\"effect\": -0.06804115768238328, \"value\": -0.7471833070360794}, \"1\": {\"effect\": 0.03204607623635694, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.05613105127667159, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10371266137497359, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.18271767564994945, \"value\": -1.5240757820298299}, \"5\": {\"effect\": -0.3004587628908263, \"value\": -1.423293582234116}, \"6\": {\"effect\": -0.13255361800960966, \"value\": -1.59692881404844}, \"7\": {\"effect\": -0.01847645495308753, \"value\": -1.6915083270593356}, \"8\": {\"effect\": -0.14258931171058692, \"value\": -1.455667112114912}, \"9\": {\"effect\": -0.027202200239250213, \"value\": -0.5692206872821983}, \"10\": {\"effect\": -0.015155435970109488, \"value\": -0.27236679075498665}, \"11\": {\"effect\": -0.026267372773359637, \"value\": 0.9610562090733883}, \"12\": {\"effect\": 0.0, \"value\": -0.28640987908208193}, \"13\": {\"effect\": -0.009804805806086253, \"value\": -0.11699412000074744}, \"14\": {\"effect\": 0.0, \"value\": 0.10411225156758794}, \"15\": {\"effect\": 0.0, \"value\": 0.22796253077908601}, \"16\": {\"effect\": 0.1380419488002726, \"value\": -1.2207415279902598}, \"17\": {\"effect\": -0.02895871848612483, \"value\": -1.1837986398181164}, \"18\": {\"effect\": -0.01508769030293039, \"value\": -0.2728623031422227}, \"19\": {\"effect\": 0.0, \"value\": -0.14894411979555344}, \"20\": {\"effect\": -0.03754821459712429, \"value\": -1.0087355486884817}, \"21\": {\"effect\": 0.017505102847431758, \"value\": 2.0205545154485467}, \"22\": {\"effect\": -0.5841859004456338, \"value\": -0.8343051231887018}}}, {\"outValue\": 2.949886567590583, \"simIndex\": 4.0, \"features\": {\"0\": {\"effect\": 0.26451487374739135, \"value\": 3.0193219206631685}, \"1\": {\"effect\": 0.0, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.050911958692503645, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.0, \"value\": 0.17723185461055793}, \"4\": {\"effect\": -0.056251058427216616, \"value\": 0.40791312638192545}, \"5\": {\"effect\": 0.1770306711674684, \"value\": 0.8432073934357639}, \"6\": {\"effect\": 0.04988954270892637, \"value\": 0.7320020904925951}, \"7\": {\"effect\": 0.0, \"value\": 0.96840950567439}, \"8\": {\"effect\": 0.08974904531162842, \"value\": 1.037838363083494}, \"9\": {\"effect\": 0.0, \"value\": -0.2801578494585561}, \"10\": {\"effect\": 0.0, \"value\": -0.5919922416333643}, \"11\": {\"effect\": 0.0, \"value\": -0.16177057587507299}, \"12\": {\"effect\": 0.0, \"value\": -0.5957897750297945}, \"13\": {\"effect\": 0.0, \"value\": -0.16432666581318173}, \"14\": {\"effect\": 0.0, \"value\": -0.8787603594748885}, \"15\": {\"effect\": 0.0, \"value\": 0.37922787693181587}, \"16\": {\"effect\": 0.0690506251981911, \"value\": -0.6674478493170267}, \"17\": {\"effect\": 0.0, \"value\": 0.37070425634680704}, \"18\": {\"effect\": 0.03282147488951337, \"value\": 0.8187344002405984}, \"19\": {\"effect\": 0.0, \"value\": -0.27315730819104117}, \"20\": {\"effect\": 0.0, \"value\": -0.2657006395129063}, \"21\": {\"effect\": 0.0, \"value\": 0.3753603005376945}, \"22\": {\"effect\": 0.7437685517869533, \"value\": 1.0802353927634942}}}, {\"outValue\": 1.1477244290693953, \"simIndex\": 35.0, \"features\": {\"0\": {\"effect\": 0.1048412693415006, \"value\": 1.1622255931170116}, \"1\": {\"effect\": 0.03200093990915197, \"value\": -0.6543830020880207}, \"2\": {\"effect\": 0.055478632710080245, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.10369054089598596, \"value\": -1.0929861506682659}, \"4\": {\"effect\": 0.12249900052654422, \"value\": -1.0287393711193897}, \"5\": {\"effect\": -0.21209974475251148, \"value\": -1.0085090899546607}, \"6\": {\"effect\": -0.09117545699238694, \"value\": -1.0864782048339665}, \"7\": {\"effect\": -0.011526522816971599, \"value\": -1.0378430458752232}, \"8\": {\"effect\": -0.08934062371969237, \"value\": -0.9035005142094729}, \"9\": {\"effect\": -0.0417999219435056, \"value\": -0.8275379877073602}, \"10\": {\"effect\": -0.03990250968029684, \"value\": -0.6733514473114969}, \"11\": {\"effect\": 0.018788920571578466, \"value\": -0.6705581209333142}, \"12\": {\"effect\": 0.0, \"value\": -0.16262547393886956}, \"13\": {\"effect\": 0.019550485451879325, \"value\": 0.2302374360792717}, \"14\": {\"effect\": 0.0, \"value\": 0.04993817064398681}, \"15\": {\"effect\": 0.11306164586542068, \"value\": 2.2815041997616072}, \"16\": {\"effect\": 0.0, \"value\": 0.00294024419541997}, \"17\": {\"effect\": -0.029806050666996747, \"value\": -1.2057303861050945}, \"18\": {\"effect\": 0.029133023514141154, \"value\": 0.567861810577786}, \"19\": {\"effect\": -0.018397759273434865, \"value\": -0.83698868887429}, \"20\": {\"effect\": 0.004516689975924443, \"value\": 0.09929360050873082}, \"21\": {\"effect\": 0.0, \"value\": -0.14534159644857383}, \"22\": {\"effect\": -0.4501890123622391, \"value\": -0.6410834072445862}}}, {\"outValue\": 1.8607847416120715, \"simIndex\": 18.0, \"features\": {\"0\": {\"effect\": -0.058401103159898105, \"value\": -0.6425581618222114}, \"1\": {\"effect\": 0.03211095916682555, \"value\": -0.6543830020880207}, \"2\": {\"effect\": -0.035480240471443825, \"value\": 0.35621640469735105}, \"3\": {\"effect\": 0.061521286305936174, \"value\": -0.6387574897767325}, \"4\": {\"effect\": -0.0341013749104494, \"value\": 0.27859494196209295}, \"5\": {\"effect\": 0.38105535182079453, \"value\": 1.7809166206246752}, \"6\": {\"effect\": 0.10240164472454766, \"value\": 1.257948521772508}, \"7\": {\"effect\": 0.017398590091299515, \"value\": 1.6537198766475916}, \"8\": {\"effect\": 0.1280410494922467, \"value\": 1.3150259952320242}, \"9\": {\"effect\": 0.046620136503802506, \"value\": 0.8217115988176572}, \"10\": {\"effect\": -0.009114058696939598, \"value\": -0.15613935407194005}, \"11\": {\"effect\": 0.025511635052944404, \"value\": -0.9106768660257073}, \"12\": {\"effect\": 0.029415084234489575, \"value\": 2.4765943201237395}, \"13\": {\"effect\": -0.05430281538703535, \"value\": -0.6471186331000134}, \"14\": {\"effect\": 0.0, \"value\": -0.6001508004392261}, \"15\": {\"effect\": -0.05741714743544907, \"value\": -1.1196741894906934}, \"16\": {\"effect\": -0.04222451325255899, \"value\": 0.3753651313823663}, \"17\": {\"effect\": 0.012987180507987528, \"value\": 0.5032587668724984}, \"18\": {\"effect\": -0.0317302338932709, \"value\": -0.5955522541790236}, \"19\": {\"effect\": 0.004679857200983684, \"value\": 0.2113025073255558}, \"20\": {\"effect\": 0.03996370037605862, \"value\": 1.0256919941296914}, \"21\": {\"effect\": -0.003932098893246916, \"value\": -0.4948935662917233}, \"22\": {\"effect\": -0.22261903028077668, \"value\": -0.3149221386498592}}}, {\"outValue\": 1.679245385775982, \"simIndex\": 20.0, \"features\": {\"0\": {\"effect\": -0.05186884705378254, \"value\": -0.5732440031180238}, \"1\": {\"effect\": -0.014026102010469187, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.05573378833679722, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.007856483247922097, \"value\": 0.1060477344679849}, \"4\": {\"effect\": -0.031150413388555353, \"value\": 0.2542173143108577}, \"5\": {\"effect\": -0.04128823601962078, \"value\": -0.20598997978511777}, \"6\": {\"effect\": -0.02631016019838775, \"value\": -0.3033740487833621}, \"7\": {\"effect\": 0.0, \"value\": 0.20262140331775583}, \"8\": {\"effect\": -0.007701945778986516, \"value\": -0.07181929635004422}, \"9\": {\"effect\": 0.04507222723380179, \"value\": 0.7934053552221108}, \"10\": {\"effect\": 0.018489876651876812, \"value\": 0.30877039266024586}, \"11\": {\"effect\": 0.0, \"value\": -0.015824399842873028}, \"12\": {\"effect\": 0.01845319865931121, \"value\": 1.5567285571328988}, \"13\": {\"effect\": 0.05191179004378128, \"value\": 0.6119270855107429}, \"14\": {\"effect\": 0.0, \"value\": 0.40206969664739356}, \"15\": {\"effect\": -0.057278557194962304, \"value\": -1.1196741894906934}, \"16\": {\"effect\": -0.06703364429372086, \"value\": 0.5955177740544523}, \"17\": {\"effect\": 0.0236782376862614, \"value\": 0.925023118545152}, \"18\": {\"effect\": -0.02518109474652557, \"value\": -0.4709749004275509}, \"19\": {\"effect\": 0.016522763251054572, \"value\": 0.7490235757489763}, \"20\": {\"effect\": 0.023835750411865118, \"value\": 0.6019378603989022}, \"21\": {\"effect\": 0.0, \"value\": -0.30012246276323457}, \"22\": {\"effect\": 0.22684235491894172, \"value\": 0.32968169231228106}}}, {\"outValue\": 1.9074823442802302, \"simIndex\": 26.0, \"features\": {\"0\": {\"effect\": -0.018035289647853496, \"value\": -0.19790129466327236}, \"1\": {\"effect\": -0.06030750975830945, \"value\": 1.2696983622603386}, \"2\": {\"effect\": 0.049258920592100915, \"value\": -0.4027111806227931}, \"3\": {\"effect\": -0.18610008652371857, \"value\": 2.01997264203881}, \"4\": {\"effect\": -0.1918752392558112, \"value\": 1.5942438305124296}, \"5\": {\"effect\": 0.3233574673865772, \"value\": 1.509025385935492}, \"6\": {\"effect\": 0.1046050438568411, \"value\": 1.2844554926938596}, \"7\": {\"effect\": 0.02032118260275214, \"value\": 1.923914343169989}, \"8\": {\"effect\": -0.05647945140819819, \"value\": -0.5720033531098144}, \"9\": {\"effect\": 0.017436585688704064, \"value\": 0.2757663392764613}, \"10\": {\"effect\": -0.012415135593558937, \"value\": -0.21425307241346336}, \"11\": {\"effect\": 0.0, \"value\": -0.09039543869144262}, \"12\": {\"effect\": 0.015946750936492605, \"value\": 1.3296012082462714}, \"13\": {\"effect\": -0.02635210206634878, \"value\": -0.3157908124129723}, \"14\": {\"effect\": 0.0, \"value\": -1.1418916096752367}, \"15\": {\"effect\": 0.03914927435186773, \"value\": 0.8055211251804202}, \"16\": {\"effect\": 0.013179699220128046, \"value\": -0.11488218864204831}, \"17\": {\"effect\": 0.013075564020498944, \"value\": 0.5032587668724984}, \"18\": {\"effect\": -0.05275828027017356, \"value\": -0.9974007320787396}, \"19\": {\"effect\": 0.02202694035214101, \"value\": 1.001990876411226}, \"20\": {\"effect\": -0.022387092664732523, \"value\": -0.6086790303737857}, \"21\": {\"effect\": 0.013800286754878092, \"value\": 1.6317029860636558}, \"22\": {\"effect\": 0.3736339331907293, \"value\": 0.5402553997827664}}}, {\"outValue\": 1.4409931529191478, \"simIndex\": 22.0, \"features\": {\"0\": {\"effect\": -0.024197947523036, \"value\": -0.26538451332621715}, \"1\": {\"effect\": -0.014163326601446057, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.05568503756746138, \"value\": -0.46159349327694216}, \"3\": {\"effect\": -0.016716974357121744, \"value\": 0.20111130421171297}, \"4\": {\"effect\": -0.04777220549634427, \"value\": 0.3925576976437019}, \"5\": {\"effect\": 0.13446666085155404, \"value\": 0.621001415428913}, \"6\": {\"effect\": 0.01731465036434647, \"value\": 0.22610907600325095}, \"7\": {\"effect\": 0.0028145323322760346, \"value\": 0.2881746533550879}, \"8\": {\"effect\": -0.09677618975008787, \"value\": -0.9823814567673927}, \"9\": {\"effect\": -0.03854663990633958, \"value\": -0.7671817715245988}, \"10\": {\"effect\": -0.021154006343961, \"value\": -0.3595373682672716}, \"11\": {\"effect\": -0.0346532210653272, \"value\": 1.251883260582809}, \"12\": {\"effect\": 0.010638133450947586, \"value\": 0.8867028779173485}, \"13\": {\"effect\": 0.023923635576055015, \"value\": 0.28059926482370157}, \"14\": {\"effect\": 0.0022596502389331807, \"value\": 1.7564217197374206}, \"15\": {\"effect\": 0.006997067043091984, \"value\": 0.16378935362338218}, \"16\": {\"effect\": -0.18372245519121846, \"value\": 1.6290121243761908}, \"17\": {\"effect\": 0.023540186247907227, \"value\": 0.925023118545152}, \"18\": {\"effect\": -0.010565691920577408, \"value\": -0.1919735352549815}, \"19\": {\"effect\": 0.010418911087296992, \"value\": 0.4728786428270968}, \"20\": {\"effect\": 0.07312543942172937, \"value\": 1.8907823633515977}, \"21\": {\"effect\": -0.002811846134804376, \"value\": -0.37126226298817905}, \"22\": {\"effect\": 0.04248887051258862, \"value\": 0.06533506362360086}}}, {\"outValue\": 1.2479512497621132, \"simIndex\": 12.0, \"features\": {\"0\": {\"effect\": -0.06399060237902722, \"value\": -0.7053332489505321}, \"1\": {\"effect\": 0.07871043002958647, \"value\": -1.6164236842622004}, \"2\": {\"effect\": 0.055832567603323655, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.03142167745128195, \"value\": -0.31430844628278004}, \"4\": {\"effect\": 0.012665292643344157, \"value\": -0.10882889371428699}, \"5\": {\"effect\": -0.048036309945767894, \"value\": -0.23819503286424415}, \"6\": {\"effect\": -0.01272188164374434, \"value\": -0.13849850200708722}, \"7\": {\"effect\": -0.006669124607736873, \"value\": -0.6148831580502095}, \"8\": {\"effect\": -0.03476445164590913, \"value\": -0.3513339163040335}, \"9\": {\"effect\": -0.04083927817600572, \"value\": -0.8113760357189355}, \"10\": {\"effect\": -0.022655609227084414, \"value\": -0.3885942274380333}, \"11\": {\"effect\": 0.03400419725781445, \"value\": -1.2089610214199853}, \"12\": {\"effect\": 0.003344889496564342, \"value\": 0.2621026684791231}, \"13\": {\"effect\": 0.012782051281449824, \"value\": 0.1480681365488857}, \"14\": {\"effect\": 0.0, \"value\": 0.7542012226508015}, \"15\": {\"effect\": -0.057170996245761364, \"value\": -1.1196741894906934}, \"16\": {\"effect\": 0.04651896947939657, \"value\": -0.4094382707357194}, \"17\": {\"effect\": -0.04168780336397371, \"value\": -1.6899158618253012}, \"18\": {\"effect\": 0.0, \"value\": 0.05242300943106745}, \"19\": {\"effect\": -0.011006278982291527, \"value\": -0.5105151830457846}, \"20\": {\"effect\": -0.027230525542583706, \"value\": -0.7378692563518435}, \"21\": {\"effect\": -0.003685113934609449, \"value\": -0.5080164420613733}, \"22\": {\"effect\": -0.1852717323013766, \"value\": -0.26157172217326097}}}, {\"outValue\": 0.865688658829016, \"simIndex\": 38.0, \"features\": {\"0\": {\"effect\": 0.019374419671322834, \"value\": 0.2179836575618529}, \"1\": {\"effect\": -0.06060104282210836, \"value\": 1.2696983622603386}, \"2\": {\"effect\": 0.05526046446244129, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.026955821415474673, \"value\": -0.2714811725415783}, \"4\": {\"effect\": -0.07559254332624425, \"value\": 0.621509263000949}, \"5\": {\"effect\": -0.07113091632153276, \"value\": -0.3444094903515189}, \"6\": {\"effect\": -0.023435062283223382, \"value\": -0.26578300749049627}, \"7\": {\"effect\": 0.0, \"value\": -0.1795805316804841}, \"8\": {\"effect\": 0.01391013554733428, \"value\": 0.15247866381340092}, \"9\": {\"effect\": -0.03894747749071306, \"value\": -0.771321179190184}, \"10\": {\"effect\": -0.02414032179483569, \"value\": -0.4079654668852082}, \"11\": {\"effect\": 0.04980562059799162, \"value\": -1.8055293322085417}, \"12\": {\"effect\": -0.01578181908744758, \"value\": -1.3194607709347583}, \"13\": {\"effect\": 0.011056119095872265, \"value\": 0.1303973194455766}, \"14\": {\"effect\": 0.0, \"value\": 0.8751900033801772}, \"15\": {\"effect\": 0.050986957678999106, \"value\": 1.0515183042772824}, \"16\": {\"effect\": 0.17427345270635797, \"value\": -1.5468935912081654}, \"17\": {\"effect\": 0.035837975173363845, \"value\": 1.4311403405523355}, \"18\": {\"effect\": 0.01138738411628562, \"value\": 0.23424250373732605}, \"19\": {\"effect\": 0.048396596085295965, \"value\": 2.22753577455853}, \"20\": {\"effect\": 0.0, \"value\": -0.14899625391537066}, \"21\": {\"effect\": 0.0, \"value\": -0.06322002123744862}, \"22\": {\"effect\": -0.8503279871108421, \"value\": -1.2149394122511281}}}, {\"outValue\": 1.448093361082052, \"simIndex\": 17.0, \"features\": {\"0\": {\"effect\": 0.059930776475466796, \"value\": 0.6652561533511386}, \"1\": {\"effect\": -0.06069067447124818, \"value\": 1.2696983622603386}, \"2\": {\"effect\": -0.10654560619378778, \"value\": 0.9922907697884681}, \"3\": {\"effect\": -0.08087059075044362, \"value\": 0.8861530146448442}, \"4\": {\"effect\": -0.07839158542423494, \"value\": 0.6454623165856895}, \"5\": {\"effect\": 0.18366247131912783, \"value\": 0.8547621042921202}, \"6\": {\"effect\": 0.024585707304229723, \"value\": 0.3172609705058355}, \"7\": {\"effect\": -0.004287975228034924, \"value\": -0.3561086084990876}, \"8\": {\"effect\": 0.07419816152631648, \"value\": 0.766645682569365}, \"9\": {\"effect\": 0.048945952213876015, \"value\": 0.8684625559819139}, \"10\": {\"effect\": -0.005836338477036573, \"value\": -0.09802563573041737}, \"11\": {\"effect\": 0.010193290580469569, \"value\": -0.37003683437357904}, \"12\": {\"effect\": 0.0, \"value\": 0.039517866570228655}, \"13\": {\"effect\": -0.0459237885111086, \"value\": -0.547720286893901}, \"14\": {\"effect\": 0.0, \"value\": -1.6700888986803468}, \"15\": {\"effect\": 0.03746550904472533, \"value\": 0.7734345366025682}, \"16\": {\"effect\": 0.03937089559973281, \"value\": -0.3493039840799177}, \"17\": {\"effect\": -0.006663485223606991, \"value\": -0.2770052837219112}, \"18\": {\"effect\": 0.06798025884454388, \"value\": 1.3126873155245258}, \"19\": {\"effect\": 0.0, \"value\": -0.1337131043106538}, \"20\": {\"effect\": 0.009463818235833643, \"value\": 0.23386038224248276}, \"21\": {\"effect\": 0.007343720106683105, \"value\": 0.8598706875066124}, \"22\": {\"effect\": -0.25423803840467524, \"value\": -0.35990118898369455}}}, {\"outValue\": 1.6044699920346157, \"simIndex\": 15.0, \"features\": {\"0\": {\"effect\": 0.17145284779403414, \"value\": 1.8972172382444341}, \"1\": {\"effect\": -0.01422092189180274, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.055655993200713266, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.026724469570319515, \"value\": -0.26564108975868717}, \"4\": {\"effect\": -0.04740768773477224, \"value\": 0.3900456344169419}, \"5\": {\"effect\": 0.04320947973959628, \"value\": 0.1921438778756905}, \"6\": {\"effect\": 0.023662360504148564, \"value\": 0.30205683450280435}, \"7\": {\"effect\": 0.0034547815643723445, \"value\": 0.3508880694498695}, \"8\": {\"effect\": 0.016470675491915873, \"value\": 0.17421036348810792}, \"9\": {\"effect\": 0.03932781192745971, \"value\": 0.6856590086326123}, \"10\": {\"effect\": 0.030442653743179893, \"value\": 0.5121684068555774}, \"11\": {\"effect\": -0.03671912413398071, \"value\": 1.3264542994313784}, \"12\": {\"effect\": 0.0, \"value\": -0.08994472229514927}, \"13\": {\"effect\": -0.05426408428454635, \"value\": -0.6471186331000134}, \"14\": {\"effect\": 0.0, \"value\": 0.8354623440362026}, \"15\": {\"effect\": -0.05739186119971834, \"value\": -1.1196741894906934}, \"16\": {\"effect\": 0.0, \"value\": -0.013978894084008561}, \"17\": {\"effect\": 0.0023842265803092344, \"value\": 0.08149441519984454}, \"18\": {\"effect\": -0.02594250630969709, \"value\": -0.48481682862215897}, \"19\": {\"effect\": -0.01617185679114505, \"value\": -0.7389804153192825}, \"20\": {\"effect\": 0.03495858814405109, \"value\": 0.8965017681516337}, \"21\": {\"effect\": 0.0, \"value\": -0.31669872689331874}, \"22\": {\"effect\": -0.1195567363950455, \"value\": -0.16719475956436716}}}, {\"outValue\": 0.982586720116035, \"simIndex\": 11.0, \"features\": {\"0\": {\"effect\": -0.07606095894491105, \"value\": -0.8387303090982139}, \"1\": {\"effect\": -0.014134415041362147, \"value\": 0.30765768008615896}, \"2\": {\"effect\": 0.05569591049613257, \"value\": -0.46159349327694216}, \"3\": {\"effect\": 0.013192989268799082, \"value\": -0.11963902018640854}, \"4\": {\"effect\": -0.025803006829166864, \"value\": 0.20960165615671014}, \"5\": {\"effect\": -0.20566008763651458, \"value\": -0.978881626220414}, \"6\": {\"effect\": -0.10302007471500149, \"value\": -1.2323212360381017}, \"7\": {\"effect\": -0.014240486320717616, \"value\": -1.306999338127505}, \"8\": {\"effect\": -0.06588987425062698, \"value\": -0.6668576865357131}, \"9\": {\"effect\": 0.006052945639538315, \"value\": 0.06438261694197926}, \"10\": {\"effect\": 0.02192565024298132, \"value\": 0.36688411100176915}, \"11\": {\"effect\": -0.03048324390564766, \"value\": 1.1027411828856697}, \"12\": {\"effect\": 0.007290910998409811, \"value\": 0.6027936918090644}, \"13\": {\"effect\": 0.04068402491106299, \"value\": 0.4793959572359264}, \"14\": {\"effect\": 0.0, \"value\": 0.32080857526199247}, \"15\": {\"effect\": -0.05732573569231808, \"value\": -1.1196741894906934}, \"16\": {\"effect\": -0.021729686106250312, \"value\": 0.19394304621740618}, \"17\": {\"effect\": -0.008041237534399781, \"value\": -0.3402699364728093}, \"18\": {\"effect\": 0.03642290976836479, \"value\": 0.7047238756019735}, \"19\": {\"effect\": -0.0224080870591446, \"value\": -1.0270452734032578}, \"20\": {\"effect\": -0.01158745123191196, \"value\": -0.32303358003571303}, \"21\": {\"effect\": -0.005075565229311796, \"value\": -0.6461519764787411}, \"22\": {\"effect\": -0.06561959322719269, \"value\": -0.08974329672698572}}}], \"plot_cmap\": \"RdBu\", \"ordering_keys\": null, \"ordering_keys_time_format\": null}),\n    document.getElementById('iWTUMCAV4SQCETPUUA61N')\n  );\n</script>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap.force_plot(svm_explainer.expected_value, svm_shap_values, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}